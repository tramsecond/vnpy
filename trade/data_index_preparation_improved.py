#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import io
import locale
import os
import time
import warnings
import numpy as np
import pandas as pd
import akshare as ak
from datetime import datetime, timedelta
import xlsxwriter
import traceback
import yfinance as yf
import pytz
import random

# å¯¼å…¥é…ç½®æ–‡ä»¶
from config import START_DATE, HOURLY_DATA_YEARS

# åŠ è½½æŠ€æœ¯æŒ‡æ ‡å‚æ•°é…ç½®
def load_technical_indicators_config():
    """ä»CSVæ–‡ä»¶åŠ è½½æŠ€æœ¯æŒ‡æ ‡å‚æ•°é…ç½®"""
    config_file = "technical_indicators_config.csv"
    
    if not os.path.exists(config_file):
        print(f"è­¦å‘Šï¼šé…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        return {}
    
    try:
        df_config = pd.read_csv(config_file, encoding='utf-8-sig')
        config_dict = {}
        
        for _, row in df_config.iterrows():
            indicator = row['æŒ‡æ ‡åç§°']
            param_name = row['å‚æ•°åç§°']
            param_value = row['å‚æ•°å€¼']
            
            # å¤„ç†ç‰¹æ®Šæ ¼å¼çš„å‚æ•°å€¼
            if param_name == 'periods' and param_value.startswith('['):
                # è§£æåˆ—è¡¨æ ¼å¼çš„å‚æ•°
                import ast
                param_value = ast.literal_eval(param_value)
            else:
                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                try:
                    param_value = float(param_value)
                    if param_value.is_integer():
                        param_value = int(param_value)
                except ValueError:
                    pass  # ä¿æŒå­—ç¬¦ä¸²æ ¼å¼
            
            if indicator not in config_dict:
                config_dict[indicator] = {}
            config_dict[indicator][param_name] = param_value
        
        print(f"æˆåŠŸåŠ è½½æŠ€æœ¯æŒ‡æ ‡é…ç½®: {config_file}")
        return config_dict
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

# å…¨å±€é…ç½®å˜é‡
TECH_CONFIG = load_technical_indicators_config()

# è§£å†³ä¸­æ–‡ç¼–ç é—®é¢˜
if sys.platform.startswith('win'):
    if sys.getdefaultencoding() != 'utf-8':
        import importlib
        importlib.reload(sys)
    if isinstance(sys.stdout, io.TextIOWrapper):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    if isinstance(sys.stderr, io.TextIOWrapper):
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    try:
        locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
    except:
        locale.setlocale(locale.LC_ALL, '')
        
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LANG'] = 'zh_CN.UTF-8'
os.environ['LC_ALL'] = 'zh_CN.UTF-8'

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# ================= é€šç”¨å‡½æ•° =================

# æŒ‡æ ‡è®¡ç®—å‡½æ•°
def calculate_macd(df, fast=None, slow=None, signal=None):
    """è®¡ç®—MACDæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if fast is None:
        fast = TECH_CONFIG.get('MACD', {}).get('fast', 12)
    if slow is None:
        slow = TECH_CONFIG.get('MACD', {}).get('slow', 26)
    if signal is None:
        signal = TECH_CONFIG.get('MACD', {}).get('signal', 9)
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    df['EMA_fast'] = df['close'].ewm(span=fast, adjust=False).mean()
    df['EMA_slow'] = df['close'].ewm(span=slow, adjust=False).mean()
    df['DIF'] = df['EMA_fast'] - df['EMA_slow']
    df['DEA'] = df['DIF'].ewm(span=signal, adjust=False).mean()
    df['MACD'] = (df['DIF'] - df['DEA']) * 2
    return df

def calculate_kdj(df, n=None, m1=None, m2=None):
    """è®¡ç®—KDJæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if n is None:
        n = TECH_CONFIG.get('KDJ', {}).get('n', 9)
    if m1 is None:
        m1 = TECH_CONFIG.get('KDJ', {}).get('m1', 3)
    if m2 is None:
        m2 = TECH_CONFIG.get('KDJ', {}).get('m2', 3)
    
    df = df.copy()
    
    # ç¡®ä¿è¾“å…¥çš„æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['high', 'low', 'close']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # è®¡ç®—æœ€ä½ä»·å’Œæœ€é«˜ä»·
    low_min = df['low'].rolling(window=n, min_periods=1).min()
    high_max = df['high'].rolling(window=n, min_periods=1).max()
    
    # è®¡ç®—RSV
    rsv = (df['close'] - low_min) / (high_max - low_min + 1e-9) * 100
    
    # ä½¿ç”¨ewmè®¡ç®—Kå’ŒDå€¼
    df['K'] = rsv.ewm(alpha=1/m1, adjust=False).mean()
    df['D'] = df['K'].ewm(alpha=1/m2, adjust=False).mean()
    df['J'] = 3 * df['K'] - 2 * df['D']
    return df

def calculate_rsi(df, periods=None):
    """è®¡ç®—RSIæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if periods is None:
        periods = TECH_CONFIG.get('RSI', {}).get('periods', 14)
    
    df = df.copy()
    
    # ç¡®ä¿è¾“å…¥çš„æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    if 'close' in df.columns:
        df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    # è®¡ç®—ä»·æ ¼å˜åŒ–
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # ä½¿ç”¨ewmè®¡ç®—å¹³å‡å¢ç›Šå’ŒæŸå¤±
    avg_gain = gain.ewm(alpha=1/periods, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/periods, adjust=False).mean()
    
    # è®¡ç®—RSå’ŒRSI
    rs = avg_gain / (avg_loss + 1e-9)
    df[f'RSI_{periods}'] = 100 - (100 / (1 + rs))
    
    # ç¡®ä¿æ²¡æœ‰NaNæˆ–æ— ç©·å¤§å€¼
    df[f'RSI_{periods}'] = df[f'RSI_{periods}'].replace([np.inf, -np.inf], np.nan)
    df[f'RSI_{periods}'] = df[f'RSI_{periods}'].ffill().bfill().fillna(50)
    
    return df

def calculate_boll(df, window=None, std_multiplier=None):
    """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if window is None:
        window = TECH_CONFIG.get('BOLL', {}).get('window', 20)
    if std_multiplier is None:
        std_multiplier = TECH_CONFIG.get('BOLL', {}).get('std_multiplier', 2)
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    df[f'MA{window}'] = df['close'].rolling(window=window).mean()
    df[f'STD{window}'] = df['close'].rolling(window=window).std()
    df['BOLL_UPPER'] = df[f'MA{window}'] + std_multiplier * df[f'STD{window}']
    df['BOLL_LOWER'] = df[f'MA{window}'] - std_multiplier * df[f'STD{window}']
    
    return df

def calculate_ma(df, periods=None):
    """è®¡ç®—ç§»åŠ¨å¹³å‡çº¿"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if periods is None:
        periods = TECH_CONFIG.get('MA', {}).get('periods', [5, 10, 20, 30, 60])
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    for period in periods:
        df[f'MA{period}'] = df['close'].rolling(window=period).mean()
    
    return df

def calculate_ema(df, periods=None):
    """è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if periods is None:
        periods = TECH_CONFIG.get('EMA', {}).get('periods', [10, 52])
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    for period in periods:
        df[f'EMA{period}'] = df['close'].ewm(span=period, adjust=False).mean()
    return df

def calculate_atr(df, period=14):
    """è®¡ç®—ATR (Average True Range)"""
    df = df.copy()
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['high', 'low', 'close']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # è®¡ç®—True Range
    high_low = df['high'] - df['low']
    high_close = np.abs(df['high'] - df['close'].shift())
    low_close = np.abs(df['low'] - df['close'].shift())
    
    # å¯¹äºç¬¬ä¸€è¡Œï¼Œhigh_closeå’Œlow_closeä¼šæ˜¯NaNï¼Œæˆ‘ä»¬ç”¨high_lowä»£æ›¿
    true_range = np.maximum(high_low, np.maximum(high_close, low_close))
    
    # å¯¹ç¬¬ä¸€è¡Œï¼Œå¦‚æœæ˜¯NaNï¼Œç”¨high_lowå¡«å……
    true_range.iloc[0] = high_low.iloc[0] if pd.isna(true_range.iloc[0]) else true_range.iloc[0]
    
    # è®¡ç®—ATRï¼Œä¿æŒç´¢å¼•ä¸€è‡´
    atr = pd.Series(true_range, index=df.index).rolling(window=period, min_periods=1).mean()
    
    return atr

def calculate_trend_indicator_a(df, ma_period=None, ma_type=None):
    """è®¡ç®—Trend Indicator A-V2 (Smoothed Heikin Ashi Cloud)"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if ma_period is None:
        ma_period = TECH_CONFIG.get('TREND_A', {}).get('ma_period', 9)  # ä¿®æ­£é»˜è®¤å€¼ä¸º9
    if ma_type is None:
        ma_type = TECH_CONFIG.get('TREND_A', {}).get('ma_type', 'EMA')
    
    df = df.copy()
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = ['open', 'high', 'low', 'close']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"  è­¦å‘Šï¼šTrend Indicator Aè®¡ç®—ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        print(f"  å½“å‰å¯ç”¨åˆ—: {list(df.columns)}")
        # è¿”å›ç©ºçš„TrendAåˆ—
        df['TREND_A_OPEN'] = np.nan
        df['TREND_A_CLOSE'] = np.nan
        df['TREND_A_HIGH'] = np.nan
        df['TREND_A_LOW'] = np.nan
        df['TREND_A_STRENGTH'] = np.nan
        df['TREND_A_DIRECTION'] = np.nan
        return df
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['open', 'high', 'low', 'close']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ•°å€¼æ•°æ®
    if df[['open', 'high', 'low', 'close']].isnull().all().any():
        print(f"  è­¦å‘Šï¼šTrend Indicator Aè®¡ç®—é‡åˆ°å…¨ç©ºæ•°æ®")
        df['TREND_A_OPEN'] = np.nan
        df['TREND_A_CLOSE'] = np.nan
        df['TREND_A_HIGH'] = np.nan
        df['TREND_A_LOW'] = np.nan
        df['TREND_A_STRENGTH'] = np.nan
        df['TREND_A_DIRECTION'] = np.nan
        return df
    
    # è®¡ç®—Heikin Ashi
    ha_close = (df['open'] + df['high'] + df['low'] + df['close']) / 4
    ha_open = pd.Series(index=df.index, dtype=float)
    ha_open.iloc[0] = (df['open'].iloc[0] + df['close'].iloc[0]) / 2
    
    for i in range(1, len(df)):
        ha_open.iloc[i] = (ha_open.iloc[i-1] + ha_close.iloc[i-1]) / 2
    
    ha_high = pd.concat([df['high'], ha_open, ha_close], axis=1).max(axis=1)
    ha_low = pd.concat([df['low'], ha_open, ha_close], axis=1).min(axis=1)
    
    # æ ¹æ®2024å¹´4æœˆ23æ—¥æ›´æ–°ï¼Œç§»é™¤åŒé‡å¹³æ»‘ï¼Œåªä½¿ç”¨å•çº§EMAå¹³æ»‘
    if ma_type == 'EMA':
        # åªä½¿ç”¨å•çº§EMAå¹³æ»‘ï¼Œå‡å°‘å»¶è¿Ÿ
        df['TREND_A_OPEN'] = ha_open.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_CLOSE'] = ha_close.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_HIGH'] = ha_high.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_LOW'] = ha_low.ewm(span=ma_period, adjust=False).mean()
    elif ma_type == 'SMA':
        # åªä½¿ç”¨å•çº§SMAå¹³æ»‘
        df['TREND_A_OPEN'] = ha_open.rolling(window=ma_period, min_periods=1).mean()
        df['TREND_A_CLOSE'] = ha_close.rolling(window=ma_period, min_periods=1).mean()
        df['TREND_A_HIGH'] = ha_high.rolling(window=ma_period, min_periods=1).mean()
        df['TREND_A_LOW'] = ha_low.rolling(window=ma_period, min_periods=1).mean()
    else:  # é»˜è®¤ä½¿ç”¨EMA
        # åªä½¿ç”¨å•çº§EMAå¹³æ»‘
        df['TREND_A_OPEN'] = ha_open.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_CLOSE'] = ha_close.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_HIGH'] = ha_high.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_LOW'] = ha_low.ewm(span=ma_period, adjust=False).mean()
    
    # è®¡ç®—è¶‹åŠ¿å¼ºåº¦ - æ ¹æ®åŸå§‹PineScripté€»è¾‘
    df['TREND_A_STRENGTH'] = 100 * (df['TREND_A_CLOSE'] - df['TREND_A_OPEN']) / (df['TREND_A_HIGH'] - df['TREND_A_LOW'] + 1e-9)
    
    # è¶‹åŠ¿æ–¹å‘ - æ ¹æ®åŸå§‹PineScripté€»è¾‘ï¼štrend > 0 ä¸ºçœ‹æ¶¨ï¼Œtrend < 0 ä¸ºçœ‹è·Œ
    df['TREND_A_DIRECTION'] = np.where(df['TREND_A_STRENGTH'] > 0, 1, -1)
    
    return df

def calculate_supertrend(df, atr_length=None, multiplier=None):
    """è®¡ç®—SuperTrendæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°
    if atr_length is None:
        atr_length = TECH_CONFIG.get('SUPERTREND', {}).get('atr_length', 10)
    if multiplier is None:
        multiplier = TECH_CONFIG.get('SUPERTREND', {}).get('multiplier', 3.0)
    
    df = df.copy()
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = ['high', 'low', 'close']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"  è­¦å‘Šï¼šSuperTrendè®¡ç®—ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        print(f"  å½“å‰å¯ç”¨åˆ—: {list(df.columns)}")
        # è¿”å›ç©ºçš„SuperTrendåˆ—
        df['SUPERTREND'] = np.nan
        df['SUPERTREND_DIRECTION'] = np.nan
        df['SUPERTREND_UPPER'] = np.nan
        df['SUPERTREND_LOWER'] = np.nan
        return df
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['high', 'low', 'close']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ•°å€¼æ•°æ®
    if df[['high', 'low', 'close']].isnull().all().any():
        print(f"  è­¦å‘Šï¼šSuperTrendè®¡ç®—é‡åˆ°å…¨ç©ºæ•°æ®")
        df['SUPERTREND'] = np.nan
        df['SUPERTREND_DIRECTION'] = np.nan
        df['SUPERTREND_UPPER'] = np.nan
        df['SUPERTREND_LOWER'] = np.nan
        return df
    
    # è®¡ç®—ATR
    atr = calculate_atr(df, atr_length)
    
    # è®¡ç®—HL2
    hl2 = (df['high'] + df['low']) / 2
    
    # è®¡ç®—åŸºç¡€ä¸Šä¸‹è½¨
    basic_upper_band = hl2 + (multiplier * atr)
    basic_lower_band = hl2 - (multiplier * atr)
    
    # åˆå§‹åŒ–æœ€ç»ˆä¸Šä¸‹è½¨
    upper_band = pd.Series(index=df.index, dtype=float)
    lower_band = pd.Series(index=df.index, dtype=float)
    
    upper_band.iloc[0] = basic_upper_band.iloc[0]
    lower_band.iloc[0] = basic_lower_band.iloc[0]
    
    # è®¡ç®—æœ€ç»ˆä¸Šä¸‹è½¨
    for i in range(1, len(df)):
        # ä¸Šè½¨è®¡ç®—
        if basic_upper_band.iloc[i] < upper_band.iloc[i-1] or df['close'].iloc[i-1] > upper_band.iloc[i-1]:
            upper_band.iloc[i] = basic_upper_band.iloc[i]
        else:
            upper_band.iloc[i] = upper_band.iloc[i-1]
        
        # ä¸‹è½¨è®¡ç®—
        if basic_lower_band.iloc[i] > lower_band.iloc[i-1] or df['close'].iloc[i-1] < lower_band.iloc[i-1]:
            lower_band.iloc[i] = basic_lower_band.iloc[i]
        else:
            lower_band.iloc[i] = lower_band.iloc[i-1]
    
    # è®¡ç®—SuperTrend
    supertrend = pd.Series(index=df.index, dtype=float)
    trend_direction = pd.Series(index=df.index, dtype=int)
    
    # åˆå§‹åŒ– - åœ¨ATRè®¡ç®—å®Œæˆä¹‹å‰ï¼Œè¶‹åŠ¿æ–¹å‘é»˜è®¤ä¸ºä¸‹é™è¶‹åŠ¿
    trend_direction.iloc[0] = -1  # ä¸‹é™è¶‹åŠ¿
    supertrend.iloc[0] = upper_band.iloc[0]
    
    for i in range(1, len(df)):
        # æ ¹æ®SuperTrend.txtçš„æ ‡å‡†é€»è¾‘
        if supertrend.iloc[i-1] == upper_band.iloc[i-1]:
            # å‰ä¸€ä¸ªSuperTrendç­‰äºå‰ä¸€ä¸ªä¸Šè½¨ï¼Œæ£€æŸ¥å½“å‰æ”¶ç›˜ä»·æ˜¯å¦çªç ´ä¸Šè½¨
            if df['close'].iloc[i] > upper_band.iloc[i]:
                trend_direction.iloc[i] = 1  # è½¬ä¸ºä¸Šå‡è¶‹åŠ¿
                supertrend.iloc[i] = lower_band.iloc[i]
            else:
                trend_direction.iloc[i] = -1  # ä¿æŒä¸‹é™è¶‹åŠ¿
                supertrend.iloc[i] = upper_band.iloc[i]
        else:
            # å‰ä¸€ä¸ªSuperTrendç­‰äºå‰ä¸€ä¸ªä¸‹è½¨ï¼Œæ£€æŸ¥å½“å‰æ”¶ç›˜ä»·æ˜¯å¦çªç ´ä¸‹è½¨
            if df['close'].iloc[i] < lower_band.iloc[i]:
                trend_direction.iloc[i] = -1  # è½¬ä¸ºä¸‹é™è¶‹åŠ¿
                supertrend.iloc[i] = upper_band.iloc[i]
            else:
                trend_direction.iloc[i] = 1  # ä¿æŒä¸Šå‡è¶‹åŠ¿
                supertrend.iloc[i] = lower_band.iloc[i]
    
    df['SUPERTREND'] = supertrend
    df['SUPERTREND_DIRECTION'] = trend_direction
    df['SUPERTREND_UPPER'] = upper_band
    df['SUPERTREND_LOWER'] = lower_band
    
    return df

def calculate_qqe_mod(df, 
                     rsi_length_primary=None, rsi_smoothing_primary=None, qqe_factor_primary=None, threshold_primary=None,
                     rsi_length_secondary=None, rsi_smoothing_secondary=None, qqe_factor_secondary=None, threshold_secondary=None,
                     bollinger_length=None, bollinger_multiplier=None):
    """è®¡ç®—QQE MODæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°
    config = TECH_CONFIG.get('QQEMOD', {})
    if rsi_length_primary is None:
        rsi_length_primary = config.get('rsi_length_primary', 6)
    if rsi_smoothing_primary is None:
        rsi_smoothing_primary = config.get('rsi_smoothing_primary', 5)
    if qqe_factor_primary is None:
        qqe_factor_primary = config.get('qqe_factor_primary', 3.0)
    if threshold_primary is None:
        threshold_primary = config.get('threshold_primary', 3.0)
    if rsi_length_secondary is None:
        rsi_length_secondary = config.get('rsi_length_secondary', 6)
    if rsi_smoothing_secondary is None:
        rsi_smoothing_secondary = config.get('rsi_smoothing_secondary', 5)
    if qqe_factor_secondary is None:
        qqe_factor_secondary = config.get('qqe_factor_secondary', 1.61)
    if threshold_secondary is None:
        threshold_secondary = config.get('threshold_secondary', 3.0)
    if bollinger_length is None:
        bollinger_length = config.get('bollinger_length', 50)
    if bollinger_multiplier is None:
        bollinger_multiplier = config.get('bollinger_multiplier', 0.35)
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    def calculate_qqe_bands(source, rsi_length, smoothing_factor, qqe_factor):
        """è®¡ç®—QQE bands"""
        wilders_length = rsi_length * 2 - 1
        
        # è®¡ç®—RSI
        delta = source.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.ewm(alpha=1/rsi_length, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1/rsi_length, adjust=False).mean()
        rs = avg_gain / (avg_loss + 1e-9)
        rsi = 100 - (100 / (1 + rs))
        
        # å¹³æ»‘RSI
        smoothed_rsi = rsi.ewm(span=smoothing_factor, adjust=False).mean()
        
        # è®¡ç®—ATR-likeæŒ‡æ ‡
        atr_rsi = np.abs(smoothed_rsi.diff())
        smoothed_atr_rsi = atr_rsi.ewm(span=wilders_length, adjust=False).mean()
        dynamic_atr_rsi = smoothed_atr_rsi * qqe_factor
        
        # åˆå§‹åŒ–bands
        long_band = pd.Series(index=source.index, dtype=float)
        short_band = pd.Series(index=source.index, dtype=float)
        trend_direction = pd.Series(index=source.index, dtype=int)
        
        # è®¡ç®—ç¬¬ä¸€ä¸ªå€¼
        long_band.iloc[0] = smoothed_rsi.iloc[0] - dynamic_atr_rsi.iloc[0]
        short_band.iloc[0] = smoothed_rsi.iloc[0] + dynamic_atr_rsi.iloc[0]
        trend_direction.iloc[0] = 1
        
        for i in range(1, len(source)):
            new_long_band = smoothed_rsi.iloc[i] - dynamic_atr_rsi.iloc[i]
            new_short_band = smoothed_rsi.iloc[i] + dynamic_atr_rsi.iloc[i]
            
            # æ›´æ–°long_band
            if smoothed_rsi.iloc[i-1] > long_band.iloc[i-1] and smoothed_rsi.iloc[i] > long_band.iloc[i-1]:
                long_band.iloc[i] = max(long_band.iloc[i-1], new_long_band)
            else:
                long_band.iloc[i] = new_long_band
            
            # æ›´æ–°short_band
            if smoothed_rsi.iloc[i-1] < short_band.iloc[i-1] and smoothed_rsi.iloc[i] < short_band.iloc[i-1]:
                short_band.iloc[i] = min(short_band.iloc[i-1], new_short_band)
            else:
                short_band.iloc[i] = new_short_band
            
            # æ›´æ–°è¶‹åŠ¿æ–¹å‘
            if smoothed_rsi.iloc[i] > short_band.iloc[i-1]:
                trend_direction.iloc[i] = 1
            elif smoothed_rsi.iloc[i] < long_band.iloc[i-1]:
                trend_direction.iloc[i] = -1
            else:
                trend_direction.iloc[i] = trend_direction.iloc[i-1]
        
        # ç¡®å®šè¶‹åŠ¿çº¿
        qqe_trend_line = pd.Series(index=source.index, dtype=float)
        for i in range(len(source)):
            qqe_trend_line.iloc[i] = long_band.iloc[i] if trend_direction.iloc[i] == 1 else short_band.iloc[i]
        
        return qqe_trend_line, smoothed_rsi
    
    # è®¡ç®—ä¸»QQE
    primary_qqe_trend, primary_rsi = calculate_qqe_bands(
        df['close'], rsi_length_primary, rsi_smoothing_primary, qqe_factor_primary
    )
    
    # è®¡ç®—å‰¯QQE
    secondary_qqe_trend, secondary_rsi = calculate_qqe_bands(
        df['close'], rsi_length_secondary, rsi_smoothing_secondary, qqe_factor_secondary
    )
    
    # è®¡ç®—å¸ƒæ—å¸¦
    bollinger_basis = (primary_qqe_trend - 50).rolling(window=bollinger_length, min_periods=1).mean()
    bollinger_deviation = bollinger_multiplier * (primary_qqe_trend - 50).rolling(window=bollinger_length, min_periods=1).std()
    bollinger_upper = bollinger_basis + bollinger_deviation
    bollinger_lower = bollinger_basis - bollinger_deviation
    
    # å­˜å‚¨ç»“æœ
    df['QQE_PRIMARY_TREND'] = primary_qqe_trend
    df['QQE_PRIMARY_RSI'] = primary_rsi
    df['QQE_SECONDARY_TREND'] = secondary_qqe_trend
    df['QQE_SECONDARY_RSI'] = secondary_rsi
    df['QQE_BOLLINGER_UPPER'] = bollinger_upper
    df['QQE_BOLLINGER_LOWER'] = bollinger_lower
    df['QQE_BOLLINGER_BASIS'] = bollinger_basis
    
    # è®¡ç®—ä¿¡å·
    df['QQE_UP_SIGNAL'] = np.where(
        (secondary_rsi - 50 > threshold_secondary) & (primary_rsi - 50 > bollinger_upper), 1, 0
    )
    df['QQE_DOWN_SIGNAL'] = np.where(
        (secondary_rsi - 50 < -threshold_secondary) & (primary_rsi - 50 < bollinger_lower), 1, 0
    )
    
    return df

def generate_hourly_view(df):
    """ç”Ÿæˆå°æ—¶çº¿æ•°æ®ï¼ˆä»æ—¥çº¿æ•°æ®ç”Ÿæˆï¼Œæ¯ä¸ªäº¤æ˜“æ—¥æŒ‰å°æ—¶åˆ†ç»„ï¼‰"""
    if df.empty:
        return pd.DataFrame()
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # ç”±äºæ—¥çº¿æ•°æ®æ²¡æœ‰å°æ—¶ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆå°æ—¶çº¿æ•°æ®
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æ—¥çº¿æ•°æ®ï¼Œä½†æ ‡è®°ä¸ºå°æ—¶çº¿ï¼ˆå®é™…æ˜¯æ—¥çº¿æ•°æ®çš„å¤åˆ¶ï¼‰
    # å¦‚æœéœ€è¦çœŸæ­£çš„å°æ—¶çº¿æ•°æ®ï¼Œéœ€è¦ä»åˆ†é’Ÿæ•°æ®èšåˆ
    hourly = df.copy()
    
    # ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆ4ä¸ªå°æ—¶çº¿æ•°æ®ç‚¹ï¼ˆ9:30, 10:30, 13:00, 14:00ï¼‰
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨æ—¥çº¿æ•°æ®ä½œä¸ºå°æ—¶çº¿æ•°æ®
    hourly_list = []
    for _, row in df.iterrows():
        date = row['date']
        # ç”Ÿæˆ4ä¸ªå°æ—¶çº¿æ•°æ®ç‚¹
        for hour in [9, 10, 13, 14]:
            hour_date = pd.Timestamp(date.year, date.month, date.day, hour, 30 if hour < 12 else 0)
            hourly_row = row.copy()
            hourly_row['date'] = hour_date
            hourly_list.append(hourly_row)
    
    if hourly_list:
        hourly = pd.DataFrame(hourly_list)
        hourly = hourly.sort_values('date')
    
    return hourly

def generate_weekly_view(df):
    """ç”Ÿæˆå‘¨çº¿æ•°æ®ï¼ˆæŒ‰äº¤æ˜“æ—¥åˆ†ç»„ï¼Œé¿å…ä¼‘æ¯æ—¥å¯¼è‡´çš„ç©ºç™½ï¼‰"""
    if df.empty:
        return pd.DataFrame()
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date')
    
    # æŒ‰å‘¨åˆ†ç»„ï¼ˆæ¯å‘¨ä»å‘¨ä¸€å¼€å§‹ï¼Œå‘¨äº”ç»“æŸï¼‰
    # ä½¿ç”¨ 'W-FRI' è¡¨ç¤ºæ¯å‘¨ä»¥å‘¨äº”ç»“æŸ
    agg_dict = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }
    # å¦‚æœå­˜åœ¨æˆäº¤é¢åˆ—ï¼Œåˆ™èšåˆæˆäº¤é¢ï¼ˆæ±‚å’Œï¼‰
    if 'amount' in df.columns:
        agg_dict['amount'] = 'sum'
    weekly = df.resample('W-FRI').agg(agg_dict)
    
    # è®¡ç®—æ¯å‘¨çš„äº¤æ˜“å¤©æ•°ï¼Œåªä¿ç•™è‡³å°‘æœ‰3ä¸ªäº¤æ˜“æ—¥çš„å‘¨
    # è¿™æ ·å¯ä»¥é¿å…ä¸å®Œæ•´çš„å‘¨ï¼ˆæ¯”å¦‚åªæœ‰1-2ä¸ªäº¤æ˜“æ—¥ï¼‰è¢«è®¡å…¥
    weekly_with_count = df.resample('W-FRI').size()
    weekly['trading_days'] = weekly_with_count
    
    # åˆ é™¤ç©ºè¡Œï¼ˆæ²¡æœ‰äº¤æ˜“æ—¥çš„å‘¨ä¼šäº§ç”Ÿç©ºè¡Œï¼‰
    weekly = weekly.dropna(subset=['open', 'high', 'low', 'close'])
    
    # åªä¿ç•™è‡³å°‘æœ‰3ä¸ªäº¤æ˜“æ—¥çš„å‘¨ï¼ˆè¿‡æ»¤æ‰ä¸å®Œæ•´çš„å‘¨ï¼‰
    weekly = weekly[weekly['trading_days'] >= 3]
    
    # åˆ é™¤è¾…åŠ©åˆ—
    weekly = weekly.drop(columns=['trading_days'], errors='ignore')
    
    # é‡ç½®ç´¢å¼•
    weekly = weekly.reset_index()
    return weekly

def generate_monthly_view(df):
    """ç”Ÿæˆæœˆçº¿æ•°æ®"""
    if df.empty:
        return pd.DataFrame()
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date')
    
    # é‡é‡‡æ ·ä¸ºæœˆçº¿
    agg_dict = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }
    # å¦‚æœå­˜åœ¨æˆäº¤é¢åˆ—ï¼Œåˆ™èšåˆæˆäº¤é¢ï¼ˆæ±‚å’Œï¼‰
    if 'amount' in df.columns:
        agg_dict['amount'] = 'sum'
    monthly = df.resample('ME').agg(agg_dict)
    
    monthly = monthly.reset_index()
    return monthly

def save_data_to_excel(df_daily, df_hourly, df_weekly, df_monthly, filename):
    """å°†æ•°æ®ä¿å­˜åˆ°Excelæ–‡ä»¶ï¼ŒåŒ…å«å¤šä¸ªå·¥ä½œè¡¨ï¼ˆå‚è€ƒdata_preparation.pyçš„å®ç°ï¼‰"""
    # ç¡®ä¿æ‰€æœ‰æ•°æ®æ¡†éƒ½æœ‰'date'åˆ—
    if 'date' not in df_daily.columns:
        if df_daily.index.name == 'date':
            df_daily = df_daily.reset_index()
        else:
            df_daily['date'] = df_daily.index
    
    if df_hourly is not None and not df_hourly.empty and 'date' not in df_hourly.columns:
        if df_hourly.index.name == 'date':
            df_hourly = df_hourly.reset_index()
        else:
            df_hourly['date'] = df_hourly.index
    
    if df_weekly is not None and not df_weekly.empty and 'date' not in df_weekly.columns:
        if df_weekly.index.name == 'date':
            df_weekly = df_weekly.reset_index()
        else:
            df_weekly['date'] = df_weekly.index
    
    if df_monthly is not None and not df_monthly.empty and 'date' not in df_monthly.columns:
        if df_monthly.index.name == 'date':
            df_monthly = df_monthly.reset_index()
        else:
            df_monthly['date'] = df_monthly.index
    
    # åˆ›å»ºExcelå†™å…¥å™¨
    try:
        with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
            # ä¿å­˜æ—¥çº¿æ•°æ®
            if not df_daily.empty:
                df_daily.to_excel(writer, sheet_name='æ—¥çº¿æ•°æ®', index=False)
            
            # ä¿å­˜å°æ—¶çº¿æ•°æ®
            if df_hourly is not None and not df_hourly.empty:
                df_hourly.to_excel(writer, sheet_name='å°æ—¶çº¿æ•°æ®', index=False)
            
            # ä¿å­˜å‘¨çº¿æ•°æ®
            if df_weekly is not None and not df_weekly.empty:
                df_weekly.to_excel(writer, sheet_name='å‘¨çº¿æ•°æ®', index=False)
            
            # ä¿å­˜æœˆçº¿æ•°æ®
            if df_monthly is not None and not df_monthly.empty:
                df_monthly.to_excel(writer, sheet_name='æœˆçº¿æ•°æ®', index=False)
        
        print(f"  æ•°æ®å·²ä¿å­˜åˆ°Excelæ–‡ä»¶: {filename}")
        
    except Exception as e:
        print(f"  ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()

def clean_and_prepare_data(df):
    """
    æ•°æ®æ¸…æ´—å’Œå‡†å¤‡ï¼ˆå‚è€ƒdata_preparation.pyçš„å®ç°ï¼‰
    :param df: åŸå§‹æ•°æ®DataFrame
    :return: æ¸…æ´—åçš„æ•°æ®
    """
    # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
    if df is None or df.empty:
        print("  âŒ è­¦å‘Š: æ•°æ®ä¸ºç©º")
        return pd.DataFrame()
    
    print("  ğŸ§¹ æ•°æ®æ¸…æ´—ä¸­...")
    
    # é‡å‘½ååˆ—ï¼ˆå‚è€ƒdata_preparation.pyçš„åˆ—åæ˜ å°„ï¼‰
    rename_map = {
        'æ—¥æœŸ': 'date',
        'æ—¶é—´': 'date',
        'æ”¶ç›˜ä»·': 'close',
        'å¼€ç›˜ä»·': 'open',
        'æœ€é«˜ä»·': 'high',
        'æœ€ä½ä»·': 'low',
        'æˆäº¤': 'volume',
        'æˆäº¤é‡': 'volume',
        'äº¤æ˜“é‡': 'volume',
        'æ”¶ç›˜': 'close',
        'å¼€ç›˜': 'open',
        'æœ€é«˜': 'high',
        'æœ€ä½': 'low',
        'Close': 'close',
        'Open': 'open',
        'High': 'high',
        'Low': 'low',
        'Volume': 'volume',
        'æˆäº¤é¢': 'amount',
        'Amount': 'amount',
        'AMOUNT': 'amount',
        'turnover': 'amount',
        'Turnover': 'amount',
        'é‡‘é¢': 'amount'
    }
    
    # åªé‡å‘½åå®é™…å­˜åœ¨çš„åˆ—
    for old_name, new_name in rename_map.items():
        if old_name in df.columns:
            df = df.rename(columns={old_name: new_name})
    
    # æ·»åŠ æ—¥æœŸåˆ—å¦‚æœä¸å­˜åœ¨
    if 'date' not in df.columns:
        if df.index.name == 'date' or df.index.name == 'æ—¥æœŸ':
            df = df.reset_index()
        else:
            df['date'] = pd.to_datetime(df.index)
    
    # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨ä¸”æœ‰æ•ˆ
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    
    # å¤„ç†æ—¶åŒºï¼šå¦‚æœæ—¥æœŸåˆ—æ˜¯tz-awareï¼Œè½¬æ¢ä¸ºUTCæ—¶åŒºç„¶åå»æ‰æ—¶åŒºä¿¡æ¯
    if pd.api.types.is_datetime64tz_dtype(df['date']):
        df['date'] = df['date'].dt.tz_convert('UTC').dt.tz_localize(None)
    
    # è¿‡æ»¤èµ·å§‹æ—¥æœŸ
    start_date_pd = pd.to_datetime(START_DATE)
    df = df[df['date'] >= start_date_pd]
    
    # æ£€æŸ¥å¹¶åˆ é™¤é‡å¤æ—¥æœŸ
    duplicate_dates = df['date'].duplicated()
    if duplicate_dates.any():
        print(f"  ğŸ” å‘ç° {duplicate_dates.sum()} ä¸ªé‡å¤æ—¥æœŸï¼Œæ­£åœ¨åˆ é™¤...")
        df = df[~duplicate_dates]
    
    # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
    for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
        if col in df.columns:
            if df[col].dtype != 'float64' and df[col].dtype != 'int64':
                df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # å‰”é™¤åœç‰Œæ—¥æˆ–é›¶äº¤æ˜“é‡æ—¥ï¼ˆå¦‚æœæœ‰volumeåˆ—ï¼‰
    if 'volume' in df.columns:
        df = df[df['volume'] > 0]
    
    # æ’åºæ•°æ®
    df = df.sort_values('date', ascending=True)
    
    # å¡«å……ç¼ºå¤±å€¼
    if df.isnull().values.any():
        print("  ğŸ”§ å‘ç°ç¼ºå¤±å€¼ï¼Œæ­£åœ¨å¡«å……...")
        for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
            if col in df.columns:
                df[col] = df[col].ffill().bfill()
        df = df.dropna()
    
    # æ£€æŸ¥å¹¶æ‰“å°æ—¥æœŸèŒƒå›´
    if len(df) > 0:
        start_date = df['date'].min()
        end_date = df['date'].max()
        print(f"  ğŸ“Š æ•°æ®é‡: {len(df)} æ¡è®°å½•")
        print(f"  ğŸ“… æ—¥æœŸèŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
    else:
        print("  âŒ è­¦å‘Šï¼šæ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return pd.DataFrame()
    
    return df

def fetch_index_data_china(index_code, max_retries=3, base_delay=1):
    """ä½¿ç”¨å›½å†…æ•°æ®æºè·å–æŒ‡æ•°æ•°æ®"""
    for attempt in range(max_retries):
        try:
            print(f"  ä½¿ç”¨å›½å†…æ•°æ®æºè·å–æŒ‡æ•°æ•°æ®({index_code})... å°è¯• {attempt + 1}/{max_retries}")
            
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            if attempt > 0:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 0.5)
                print(f"  ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            
            # æ ¹æ®æŒ‡æ•°ä»£ç é€‰æ‹©ä¸åŒçš„è·å–æ–¹æ³•
            if index_code == 'sh000001':
                # ä¸Šè¯æŒ‡æ•° - ä½¿ç”¨æ–°æµªæ•°æ®æº
                df_data = ak.stock_zh_index_daily(symbol="sh000001")
            elif index_code == 'sz399001':
                # æ·±è¯æˆæŒ‡ - ä½¿ç”¨æ–°æµªæ•°æ®æº
                df_data = ak.stock_zh_index_daily(symbol="sz399001")
            elif index_code == 'sz399006':
                # åˆ›ä¸šæ¿æŒ‡ - ä½¿ç”¨æ–°æµªæ•°æ®æº
                df_data = ak.stock_zh_index_daily(symbol="sz399006")
            elif index_code == 'bj899050':
                # åŒ—è¯50 - ä½¿ç”¨æ–°æµªæ•°æ®æº
                df_data = ak.stock_zh_index_daily(symbol="bj899050")
            elif index_code == 'sh000688':
                # ç§‘åˆ›50 - ä½¿ç”¨æ–°æµªæ•°æ®æº
                df_data = ak.stock_zh_index_daily(symbol="sh000688")
            elif index_code == '^HSI':
                # æ’ç”ŸæŒ‡æ•° - ä½¿ç”¨æ–°æµªæ¸¯è‚¡æŒ‡æ•°æ•°æ®
                df_data = ak.stock_hk_index_daily_sina(symbol="HSI")
            elif index_code == '^HSTECH':
                # æ’ç”Ÿç§‘æŠ€ - ä½¿ç”¨æ–°æµªæ¸¯è‚¡æŒ‡æ•°æ•°æ®
                df_data = ak.stock_hk_index_daily_sina(symbol="HSTECH")
            elif index_code == '^DJI':
                # é“ç¼æ–¯ - ä½¿ç”¨æ–°æµªç¾è‚¡æŒ‡æ•°æ•°æ®
                df_data = ak.index_us_stock_sina(symbol=".DJI")
            elif index_code == '^IXIC':
                # çº³æ–¯è¾¾å…‹æŒ‡æ•° - ä½¿ç”¨æ–°æµªç¾è‚¡æŒ‡æ•°æ•°æ®
                df_data = ak.index_us_stock_sina(symbol=".IXIC")
            elif index_code == '^GSPC':
                # æ ‡æ™®500 - ä½¿ç”¨æ–°æµªç¾è‚¡æŒ‡æ•°æ•°æ®
                df_data = ak.index_us_stock_sina(symbol=".INX")
            else:
                # å…¶ä»–æŒ‡æ•°å°è¯•é€šç”¨æ–¹æ³•
                try:
                    df_data = ak.stock_zh_index_daily(symbol=index_code)
                except:
                    df_data = pd.DataFrame()
            
            if not df_data.empty:
                # ç»Ÿä¸€æ•°æ®æ ¼å¼ - å¤„ç†å„ç§å¯èƒ½çš„åˆ—å
                column_mapping = {}
                
                # æ—¥æœŸåˆ—æ˜ å°„
                date_cols = ['date', 'æ—¥æœŸ', 'Date', 'DATE', 'time', 'Time', 'TIME', 'datetime', 'DateTime']
                for col in date_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'date'
                        break
                
                # å¼€ç›˜ä»·åˆ—æ˜ å°„
                open_cols = ['open', 'å¼€ç›˜', 'Open', 'OPEN', 'o', 'O']
                for col in open_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'open'
                        break
                
                # æœ€é«˜ä»·åˆ—æ˜ å°„
                high_cols = ['high', 'æœ€é«˜', 'High', 'HIGH', 'h', 'H']
                for col in high_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'high'
                        break
                
                # æœ€ä½ä»·åˆ—æ˜ å°„
                low_cols = ['low', 'æœ€ä½', 'Low', 'LOW', 'l', 'L']
                for col in low_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'low'
                        break
                
                # æ”¶ç›˜ä»·åˆ—æ˜ å°„
                close_cols = ['close', 'æ”¶ç›˜', 'Close', 'CLOSE', 'c', 'C', 'price', 'Price']
                for col in close_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'close'
                        break
                
                # æˆäº¤é‡åˆ—æ˜ å°„ï¼ˆå¯é€‰ï¼‰
                volume_cols = ['volume', 'æˆäº¤é‡', 'Volume', 'VOLUME', 'v', 'V', 'vol', 'Vol']
                for col in volume_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'volume'
                        break
                
                # æˆäº¤é¢åˆ—æ˜ å°„ï¼ˆå¯é€‰ï¼‰
                amount_cols = ['amount', 'æˆäº¤é¢', 'Amount', 'AMOUNT', 'turnover', 'Turnover', 'æˆäº¤', 'é‡‘é¢']
                for col in amount_cols:
                    if col in df_data.columns:
                        column_mapping[col] = 'amount'
                        break
                
                # åº”ç”¨åˆ—åæ˜ å°„
                if column_mapping:
                    df_data = df_data.rename(columns=column_mapping)
                
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                required_cols = ['date', 'open', 'high', 'low', 'close']
                if all(col in df_data.columns for col in required_cols):
                    print(f"  æˆåŠŸè·å–æ•°æ®ï¼Œå…± {len(df_data)} è¡Œ")
                    return df_data
                else:
                    missing_cols = [col for col in required_cols if col not in df_data.columns]
                    print(f"  æ•°æ®æ ¼å¼ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                    print(f"  å½“å‰å¯ç”¨åˆ—: {list(df_data.columns)}")
            else:
                print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼šæ•°æ®ä¸ºç©º")
                
        except Exception as e:
            error_msg = str(e)
            print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼š{error_msg}")
            
            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
            if attempt == max_retries - 1:
                print(f"  æ‰€æœ‰ {max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
                return None
    
    return None

def fetch_index_data_hourly_china(index_code, max_retries=3, base_delay=1):
    """ä½¿ç”¨å›½å†…æ•°æ®æºè·å–æŒ‡æ•°å°æ—¶çº¿æ•°æ®"""
    for attempt in range(max_retries):
        try:
            print(f"  ä½¿ç”¨å›½å†…æ•°æ®æºè·å–æŒ‡æ•°å°æ—¶çº¿æ•°æ®({index_code})... å°è¯• {attempt + 1}/{max_retries}")
            
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            if attempt > 0:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 0.5)
                print(f"  ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            
            # å°è¯•è·å–åˆ†é’Ÿæ•°æ®ç„¶åèšåˆä¸ºå°æ—¶çº¿
            df_hourly = pd.DataFrame()
            
            # æ ¹æ®æŒ‡æ•°ä»£ç é€‰æ‹©ä¸åŒçš„è·å–æ–¹æ³•
            # ä½¿ç”¨ index_zh_a_hist_min_em æ¥å£è·å–å°æ—¶çº¿æ•°æ®ï¼ˆperiod="60"è¡¨ç¤º60åˆ†é’Ÿï¼‰
            # æ³¨æ„ï¼šè¯¥æ¥å£åªèƒ½è¿”å›è¿‘æœŸæ•°æ®ï¼Œä¸èƒ½è¿”å›æ‰€æœ‰å†å²æ•°æ®
            index_code_clean = index_code.replace('sh', '').replace('sz', '').replace('bj', '')
            
            # è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆå°è¯•è·å–æœ€è¿‘Nå¹´çš„æ•°æ®ï¼Œé€æ­¥å›é€€ï¼‰
            end_date = datetime.now()
            max_days = HOURLY_DATA_YEARS * 365  # é…ç½®çš„å¹´æ•°è½¬æ¢ä¸ºå¤©æ•°
            
            # å°è¯•å¤šä¸ªæ—¶é—´èŒƒå›´ï¼Œä»æœ€é•¿åˆ°æœ€çŸ­
            time_ranges = [
                max_days,      # é…ç½®çš„å¹´æ•°
                int(max_days * 0.75),  # 75%
                int(max_days * 0.5),   # 50%
                int(max_days * 0.25),  # 25%
                90,            # 3ä¸ªæœˆ
                30,            # 1ä¸ªæœˆ
            ]
            
            df_minute = pd.DataFrame()
            for days in time_ranges:
                try:
                    start_date = end_date - timedelta(days=days)
                    start_date_str = start_date.strftime("%Y-%m-%d 09:30:00")
                    end_date_str = end_date.strftime("%Y-%m-%d 15:00:00")
                    
                    print(f"    å°è¯•è·å–æœ€è¿‘ {days} å¤©çš„å°æ—¶çº¿æ•°æ®...")
                    # ä½¿ç”¨ index_zh_a_hist_min_em è·å–60åˆ†é’Ÿæ•°æ®
                    df_minute = ak.index_zh_a_hist_min_em(
                        symbol=index_code_clean, 
                        period="60", 
                        start_date=start_date_str, 
                        end_date=end_date_str
                    )
                    if not df_minute.empty:
                        df_hourly = df_minute.copy()
                        print(f"    âœ… æˆåŠŸè·å–å°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
                        break
                except Exception as e:
                    print(f"    âš ï¸  è·å–æœ€è¿‘ {days} å¤©æ•°æ®å¤±è´¥: {str(e)[:50]}")
                    continue
            
            if df_minute.empty:
                print(f"    âŒ æ‰€æœ‰æ—¶é—´èŒƒå›´éƒ½å¤±è´¥ï¼Œå°†ä½¿ç”¨æ—¥çº¿æ•°æ®ç”Ÿæˆå°æ—¶çº¿")
            
            if not df_hourly.empty:
                # ç»Ÿä¸€æ•°æ®æ ¼å¼ - index_zh_a_hist_min_em è¿”å›çš„åˆ—åæ˜¯ä¸­æ–‡
                column_mapping = {
                    'æ—¶é—´': 'date',
                    'å¼€ç›˜': 'open',
                    'æ”¶ç›˜': 'close',
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'æˆäº¤é‡': 'volume',
                    'æˆäº¤é¢': 'amount',
                    'å‡ä»·': 'average'
                }
                
                # æ£€æŸ¥å¹¶åº”ç”¨åˆ—åæ˜ å°„
                available_mapping = {k: v for k, v in column_mapping.items() if k in df_hourly.columns}
                if available_mapping:
                    df_hourly = df_hourly.rename(columns=available_mapping)
                
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                required_cols = ['date', 'open', 'high', 'low', 'close']
                if all(col in df_hourly.columns for col in required_cols):
                    print(f"  æˆåŠŸè·å–å°æ—¶çº¿æ•°æ®ï¼Œå…± {len(df_hourly)} è¡Œ")
                    return df_hourly
                else:
                    missing_cols = [col for col in required_cols if col not in df_hourly.columns]
                    print(f"  å°æ—¶çº¿æ•°æ®æ ¼å¼ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                    print(f"  å½“å‰å¯ç”¨åˆ—: {list(df_hourly.columns)}")
            else:
                print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼šå°æ—¶çº¿æ•°æ®ä¸ºç©º")
                
        except Exception as e:
            error_msg = str(e)
            print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼š{error_msg}")
            
            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
            if attempt == max_retries - 1:
                print(f"  æ‰€æœ‰ {max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
                return None
    
    return None

def fetch_index_data_hourly_hk(index_code, max_retries=3, base_delay=1):
    """è·å–æ’ç”ŸæŒ‡æ•°å°æ—¶çº¿æ•°æ®"""
    for attempt in range(max_retries):
        try:
            print(f"  è·å–æ’ç”ŸæŒ‡æ•°å°æ—¶çº¿æ•°æ®({index_code})... å°è¯• {attempt + 1}/{max_retries}")
            
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            if attempt > 0:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 0.5)
                print(f"  ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            
            df_hourly = pd.DataFrame()
            
            # æ’ç”ŸæŒ‡æ•°ä»£ç æ˜ å°„ï¼ˆyfinanceä½¿ç”¨çš„ä»£ç ï¼‰
            symbol_map = {
                '^HSI': '^HSI',  # æ’ç”ŸæŒ‡æ•°
                '^HSTECH': '^HSTECH'  # æ’ç”Ÿç§‘æŠ€ï¼ˆyfinanceä¸­å¯èƒ½ä¸æ”¯æŒï¼Œå°è¯•å…¶ä»–ä»£ç ï¼‰
            }
            
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨yfinanceè·å–å°æ—¶çº¿æ•°æ®
            try:
                import yfinance as yf
                # å¯¹äºæ’ç”Ÿç§‘æŠ€ï¼Œå°è¯•ä¸åŒçš„ä»£ç æ ¼å¼
                if index_code == '^HSTECH':
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„ä»£ç æ ¼å¼ï¼ˆå·²éªŒè¯ï¼šHSTECH.HK æ˜¯æœ‰æ•ˆä»£ç ï¼‰
                    ticker_codes = [
                        'HSTECH.HK',    # æ¸¯è‚¡æ ¼å¼ï¼ˆå·²éªŒè¯æœ‰æ•ˆï¼ï¼‰
                        '^HSTECH',      # æ ‡å‡†æ ¼å¼
                        'HSTECH',       # æ— å‰ç¼€
                    ]
                else:
                    ticker_codes = [index_code]
                
                ticker = None
                df_hourly_temp = pd.DataFrame()
                for ticker_code in ticker_codes:
                    try:
                        ticker = yf.Ticker(ticker_code)
                        # å°è¯•è·å–æœ€è¿‘Nå¹´çš„å°æ—¶çº¿æ•°æ®ï¼Œé€æ­¥å›é€€
                        end_date = datetime.now()
                        max_days = HOURLY_DATA_YEARS * 365
                        
                        # å°è¯•å¤šä¸ªæ—¶é—´èŒƒå›´ï¼Œä»æœ€é•¿åˆ°æœ€çŸ­
                        time_ranges = [
                            (max_days, f"{HOURLY_DATA_YEARS}y"),      # é…ç½®çš„å¹´æ•°
                            (int(max_days * 0.75), "18mo"),           # 18ä¸ªæœˆ
                            (int(max_days * 0.5), "1y"),              # 1å¹´
                            (int(max_days * 0.25), "6mo"),            # 6ä¸ªæœˆ
                            (90, "3mo"),                               # 3ä¸ªæœˆ
                            (30, "1mo"),                               # 1ä¸ªæœˆ
                        ]
                        
                        df_hourly_temp = pd.DataFrame()
                        for days, period in time_ranges:
                            try:
                                start_date = end_date - timedelta(days=days)
                                print(f"    å°è¯•è·å–æœ€è¿‘ {days} å¤©çš„å°æ—¶çº¿æ•°æ®ï¼ˆ{period}ï¼‰...")
                                
                                # å…ˆå°è¯•ä½¿ç”¨startå’Œendå‚æ•°
                                try:
                                    df_hourly_temp = ticker.history(
                                        start=start_date.strftime("%Y-%m-%d"),
                                        end=end_date.strftime("%Y-%m-%d"),
                                        interval="1h"
                                    )
                                except:
                                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨periodå‚æ•°
                                    df_hourly_temp = ticker.history(period=period, interval="1h")
                                
                                if not df_hourly_temp.empty:
                                    print(f"    âœ… æˆåŠŸè·å–å°æ—¶çº¿æ•°æ®: {len(df_hourly_temp)} æ¡ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
                                    break
                            except Exception as e:
                                print(f"    âš ï¸  è·å–æœ€è¿‘ {days} å¤©æ•°æ®å¤±è´¥: {str(e)[:50]}")
                                continue
                        
                        if not df_hourly_temp.empty:
                            print(f"    ä½¿ç”¨ä»£ç  {ticker_code} æˆåŠŸè·å–æ•°æ®")
                            break
                    except:
                        continue
                
                if not df_hourly_temp.empty:
                    df_hourly = df_hourly_temp
                    # è½¬æ¢åˆ—å
                    df_hourly = df_hourly.reset_index()
                    df_hourly.columns = [col.lower().replace(' ', '_') for col in df_hourly.columns]
                    # é‡å‘½åæ—¥æœŸåˆ—
                    if 'datetime' in df_hourly.columns:
                        df_hourly = df_hourly.rename(columns={'datetime': 'date'})
                    elif 'date' not in df_hourly.columns and df_hourly.index.name == 'Date':
                        df_hourly = df_hourly.reset_index()
                        df_hourly = df_hourly.rename(columns={'Date': 'date'})
                    
                    # ç¡®ä¿åˆ—åæ­£ç¡®
                    column_mapping = {
                        'open': 'open',
                        'high': 'high',
                        'low': 'low',
                        'close': 'close',
                        'volume': 'volume'
                    }
                    for old_col, new_col in column_mapping.items():
                        if old_col in df_hourly.columns and new_col not in df_hourly.columns:
                            df_hourly = df_hourly.rename(columns={old_col: new_col})
                    
                    print(f"    æˆåŠŸé€šè¿‡yfinanceè·å–å°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡")
            except Exception as e:
                print(f"    yfinanceè·å–å¤±è´¥: {e}")
            
            if not df_hourly.empty:
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                required_cols = ['date', 'open', 'high', 'low', 'close']
                if all(col in df_hourly.columns for col in required_cols):
                    print(f"  æˆåŠŸè·å–æ’ç”ŸæŒ‡æ•°å°æ—¶çº¿æ•°æ®ï¼Œå…± {len(df_hourly)} è¡Œ")
                    return df_hourly
                else:
                    missing_cols = [col for col in required_cols if col not in df_hourly.columns]
                    print(f"  å°æ—¶çº¿æ•°æ®æ ¼å¼ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
            else:
                print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼šå°æ—¶çº¿æ•°æ®ä¸ºç©º")
                
        except Exception as e:
            error_msg = str(e)
            print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼š{error_msg}")
            
            if attempt == max_retries - 1:
                print(f"  æ‰€æœ‰ {max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
                return None
    
    return None

def fetch_index_data_hourly_us(index_code, max_retries=3, base_delay=1):
    """è·å–ç¾è‚¡æŒ‡æ•°å°æ—¶çº¿æ•°æ®"""
    for attempt in range(max_retries):
        try:
            print(f"  è·å–ç¾è‚¡æŒ‡æ•°å°æ—¶çº¿æ•°æ®({index_code})... å°è¯• {attempt + 1}/{max_retries}")
            
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            if attempt > 0:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 0.5)
                print(f"  ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            
            df_hourly = pd.DataFrame()
            
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨yfinanceè·å–å°æ—¶çº¿æ•°æ®
            try:
                import yfinance as yf
                ticker = yf.Ticker(index_code)
                # å°è¯•è·å–æœ€è¿‘Nå¹´çš„å°æ—¶çº¿æ•°æ®ï¼Œé€æ­¥å›é€€
                end_date = datetime.now()
                max_days = HOURLY_DATA_YEARS * 365
                
                # å°è¯•å¤šä¸ªæ—¶é—´èŒƒå›´ï¼Œä»æœ€é•¿åˆ°æœ€çŸ­
                time_ranges = [
                    (max_days, f"{HOURLY_DATA_YEARS}y"),      # é…ç½®çš„å¹´æ•°
                    (int(max_days * 0.75), "18mo"),           # 18ä¸ªæœˆ
                    (int(max_days * 0.5), "1y"),              # 1å¹´
                    (int(max_days * 0.25), "6mo"),            # 6ä¸ªæœˆ
                    (90, "3mo"),                               # 3ä¸ªæœˆ
                    (30, "1mo"),                               # 1ä¸ªæœˆ
                ]
                
                df_hourly = pd.DataFrame()
                for days, period in time_ranges:
                    try:
                        start_date = end_date - timedelta(days=days)
                        print(f"    å°è¯•è·å–æœ€è¿‘ {days} å¤©çš„å°æ—¶çº¿æ•°æ®ï¼ˆ{period}ï¼‰...")
                        
                        # å…ˆå°è¯•ä½¿ç”¨startå’Œendå‚æ•°
                        try:
                            df_hourly = ticker.history(
                                start=start_date.strftime("%Y-%m-%d"),
                                end=end_date.strftime("%Y-%m-%d"),
                                interval="1h"
                            )
                        except:
                            # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨periodå‚æ•°
                            df_hourly = ticker.history(period=period, interval="1h")
                        
                        if not df_hourly.empty:
                            print(f"    âœ… æˆåŠŸè·å–å°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
                            break
                    except Exception as e:
                        print(f"    âš ï¸  è·å–æœ€è¿‘ {days} å¤©æ•°æ®å¤±è´¥: {str(e)[:50]}")
                        continue
                if not df_hourly.empty:
                    # è½¬æ¢åˆ—å
                    df_hourly = df_hourly.reset_index()
                    df_hourly.columns = [col.lower().replace(' ', '_') for col in df_hourly.columns]
                    # é‡å‘½åæ—¥æœŸåˆ—
                    if 'datetime' in df_hourly.columns:
                        df_hourly = df_hourly.rename(columns={'datetime': 'date'})
                    elif 'date' not in df_hourly.columns and df_hourly.index.name == 'Date':
                        df_hourly = df_hourly.reset_index()
                        df_hourly = df_hourly.rename(columns={'Date': 'date'})
                    
                    # ç¡®ä¿åˆ—åæ­£ç¡®
                    column_mapping = {
                        'open': 'open',
                        'high': 'high',
                        'low': 'low',
                        'close': 'close',
                        'volume': 'volume'
                    }
                    for old_col, new_col in column_mapping.items():
                        if old_col in df_hourly.columns and new_col not in df_hourly.columns:
                            df_hourly = df_hourly.rename(columns={old_col: new_col})
                    
                    print(f"    æˆåŠŸé€šè¿‡yfinanceè·å–å°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡")
            except Exception as e:
                print(f"    yfinanceè·å–å¤±è´¥: {e}")
            
            if not df_hourly.empty:
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                required_cols = ['date', 'open', 'high', 'low', 'close']
                if all(col in df_hourly.columns for col in required_cols):
                    print(f"  æˆåŠŸè·å–ç¾è‚¡æŒ‡æ•°å°æ—¶çº¿æ•°æ®ï¼Œå…± {len(df_hourly)} è¡Œ")
                    return df_hourly
                else:
                    missing_cols = [col for col in required_cols if col not in df_hourly.columns]
                    print(f"  å°æ—¶çº¿æ•°æ®æ ¼å¼ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
            else:
                print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼šå°æ—¶çº¿æ•°æ®ä¸ºç©º")
                
        except Exception as e:
            error_msg = str(e)
            print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼š{error_msg}")
            
            if attempt == max_retries - 1:
                print(f"  æ‰€æœ‰ {max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
                return None
    
    return None

def fetch_index_data(index_code, name, source='yfinance'):
    """è·å–æŒ‡æ•°æ•°æ®"""
    print(f"ğŸ“Š è·å–æŒ‡æ•°æ•°æ®: {name}({index_code})")
    
    # è·å–æ—¥çº¿æ•°æ®
    df_data = pd.DataFrame()
    
    try:
        # å¯¹äºæ‰€æœ‰å›½å†…æ•°æ®æºï¼ˆåŒ…æ‹¬Aè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰ï¼Œéƒ½ä½¿ç”¨fetch_index_data_chinaå‡½æ•°
        # è¯¥å‡½æ•°ä½¿ç”¨æ–°æµªæ•°æ®æºï¼Œå¹¶å¸¦æœ‰é‡è¯•æœºåˆ¶
        if source == 'china':
            print(f"  ğŸ“¥ ä½¿ç”¨æ–°æµªæ•°æ®æºè·å–{name}æ—¥çº¿æ•°æ®...")
            df_data = fetch_index_data_china(index_code)
            
            if df_data is None or df_data.empty:
                print(f"  âŒ æ— æ³•è·å–{name}æ•°æ®")
                return False
                
        elif source == 'hk':
            print(f"  ğŸ“¥ è·å–{name}æ—¥çº¿æ•°æ®...")
            df_data = ak.stock_hk_index_daily_em(symbol=index_code.replace('^', ''))
                
        elif source == 'us':
            print(f"  ğŸ“¥ è·å–{name}æ—¥çº¿æ•°æ®...")
            # å°è¯•ä¸åŒçš„ç¬¦å·æ ¼å¼
            try:
                df_data = ak.stock_us_hist_min_em(symbol=f"{index_code}.NASDAQ")
            except:
                try:
                    df_data = ak.stock_us_hist_min_em(symbol=index_code)
                except:
                    print(f"  âŒ æ— æ³•è·å–{name}æ•°æ®ï¼Œè·³è¿‡")
                    return False
        
        if df_data is not None and not df_data.empty:
            print(f"  âœ… æˆåŠŸè·å–æ—¥çº¿æ•°æ®: {len(df_data)}æ¡")
        else:
            print(f"  âŒ æ— æ³•è·å–{name}æ•°æ®")
            return False
            
    except Exception as e:
        print(f"  âŒ è·å–{name}æ•°æ®å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    # æ•°æ®æ¸…æ´—å’Œå‡†å¤‡
    if df_data is not None and not df_data.empty:
        print(f"  ğŸ§¹ æ¸…æ´—{name}æ•°æ®...")
        df_data = clean_and_prepare_data(df_data)
        
        # è®¡ç®—æ—¥çº¿æŠ€æœ¯æŒ‡æ ‡
        print(f"  ğŸ§® è®¡ç®—{name}æ—¥çº¿æŠ€æœ¯æŒ‡æ ‡...")
        try:
            df_data = calculate_ma(df_data)
            df_data = calculate_ema(df_data)
            df_data = calculate_macd(df_data)
            df_data = calculate_kdj(df_data)
            df_data = calculate_rsi(df_data)
            df_data = calculate_boll(df_data)
            df_data = calculate_trend_indicator_a(df_data)
            df_data = calculate_supertrend(df_data)
            df_data = calculate_qqe_mod(df_data)
            print(f"  âœ… {name}æ—¥çº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
        except Exception as e:
            print(f"  âš ï¸  è®¡ç®—æ—¥çº¿æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            traceback.print_exc()
        
        # è·å–å°æ—¶çº¿æ•°æ®
        print(f"  ğŸ“ˆ è·å–{name}å°æ—¶çº¿æ•°æ®...")
        df_hourly = pd.DataFrame()
        
        # æ ¹æ®æŒ‡æ•°ä»£ç åˆ¤æ–­æ•°æ®æºç±»å‹ï¼ˆå› ä¸ºæ’ç”Ÿå’Œç¾è‚¡åœ¨fetch_index_dataä¸­sourceæ˜¯'china'ï¼Œä½†å®é™…éœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        if index_code in ['^HSI', '^HSTECH']:
            # æ’ç”ŸæŒ‡æ•°ä½¿ç”¨ä¸“é—¨çš„å‡½æ•°
            df_hourly = fetch_index_data_hourly_hk(index_code)
            # å¦‚æœæ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ
            if df_hourly is None or df_hourly.empty:
                print(f"  âš ï¸  æ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
                df_hourly = generate_hourly_view(df_data.copy())
        elif index_code in ['^DJI', '^IXIC', '^GSPC']:
            # ç¾è‚¡æŒ‡æ•°ä½¿ç”¨ä¸“é—¨çš„å‡½æ•°
            df_hourly = fetch_index_data_hourly_us(index_code)
            # å¦‚æœæ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ
            if df_hourly is None or df_hourly.empty:
                print(f"  âš ï¸  æ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
                df_hourly = generate_hourly_view(df_data.copy())
        elif source == 'china':
            # å›½å†…Aè‚¡æŒ‡æ•°
            df_hourly = fetch_index_data_hourly_china(index_code)
            # å¦‚æœæ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ
            if df_hourly is None or df_hourly.empty:
                print(f"  âš ï¸  æ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
                df_hourly = generate_hourly_view(df_data.copy())
        elif source == 'hk':
            # æ’ç”ŸæŒ‡æ•°ä½¿ç”¨ä¸“é—¨çš„å‡½æ•°
            df_hourly = fetch_index_data_hourly_hk(index_code)
            # å¦‚æœæ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ
            if df_hourly is None or df_hourly.empty:
                print(f"  âš ï¸  æ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
                df_hourly = generate_hourly_view(df_data.copy())
        elif source == 'us':
            # ç¾è‚¡æŒ‡æ•°ä½¿ç”¨ä¸“é—¨çš„å‡½æ•°
            df_hourly = fetch_index_data_hourly_us(index_code)
            # å¦‚æœæ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ
            if df_hourly is None or df_hourly.empty:
                print(f"  âš ï¸  æ— æ³•è·å–å°æ—¶çº¿æ•°æ®ï¼Œä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
                df_hourly = generate_hourly_view(df_data.copy())
        else:
            # å…¶ä»–æ•°æ®æºæš‚æ—¶ä»æ—¥çº¿æ•°æ®ç”Ÿæˆå°æ—¶çº¿
            df_hourly = generate_hourly_view(df_data.copy())
        
        # è®¡ç®—å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡
        if not df_hourly.empty:
            print(f"  ğŸ§® è®¡ç®—{name}å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡...")
            try:
                df_hourly = clean_and_prepare_data(df_hourly)
                df_hourly = calculate_ma(df_hourly)
                df_hourly = calculate_ema(df_hourly)
                df_hourly = calculate_macd(df_hourly)
                df_hourly = calculate_kdj(df_hourly)
                df_hourly = calculate_rsi(df_hourly)
                df_hourly = calculate_boll(df_hourly)
                df_hourly = calculate_trend_indicator_a(df_hourly)
                df_hourly = calculate_supertrend(df_hourly)
                df_hourly = calculate_qqe_mod(df_hourly)
                print(f"  âœ… {name}å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸  è®¡ç®—å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                traceback.print_exc()
        
        # ç”Ÿæˆå‘¨çº¿è§†å›¾
        print(f"  ğŸ“ˆ ç”Ÿæˆ{name}å‘¨çº¿æ•°æ®...")
        df_weekly = generate_weekly_view(df_data.copy())
        
        # è®¡ç®—å‘¨çº¿æŠ€æœ¯æŒ‡æ ‡
        if not df_weekly.empty:
            print(f"  ğŸ§® è®¡ç®—{name}å‘¨çº¿æŠ€æœ¯æŒ‡æ ‡...")
            try:
                df_weekly = calculate_ma(df_weekly)
                df_weekly = calculate_ema(df_weekly)
                df_weekly = calculate_macd(df_weekly)
                df_weekly = calculate_kdj(df_weekly)
                df_weekly = calculate_rsi(df_weekly)
                df_weekly = calculate_boll(df_weekly)
                df_weekly = calculate_trend_indicator_a(df_weekly)
                df_weekly = calculate_supertrend(df_weekly)
                df_weekly = calculate_qqe_mod(df_weekly)
                print(f"  âœ… {name}å‘¨çº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸  è®¡ç®—å‘¨çº¿æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                traceback.print_exc()
        
        # ç”Ÿæˆæœˆçº¿è§†å›¾
        print(f"  ğŸ“ˆ ç”Ÿæˆ{name}æœˆçº¿æ•°æ®...")
        df_monthly = generate_monthly_view(df_data.copy())
        
        # è®¡ç®—æœˆçº¿æŠ€æœ¯æŒ‡æ ‡
        if not df_monthly.empty:
            print(f"  ğŸ§® è®¡ç®—{name}æœˆçº¿æŠ€æœ¯æŒ‡æ ‡...")
            try:
                df_monthly = calculate_ma(df_monthly)
                df_monthly = calculate_ema(df_monthly)
                df_monthly = calculate_macd(df_monthly)
                df_monthly = calculate_kdj(df_monthly)
                df_monthly = calculate_rsi(df_monthly)
                df_monthly = calculate_boll(df_monthly)
                df_monthly = calculate_trend_indicator_a(df_monthly)
                df_monthly = calculate_supertrend(df_monthly)
                df_monthly = calculate_qqe_mod(df_monthly)
                print(f"  âœ… {name}æœˆçº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸  è®¡ç®—æœˆçº¿æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                traceback.print_exc()
        
        # ä¿å­˜æ•°æ®åˆ°Excel
        excel_file = f"index_data/{name}_{index_code}_data.xlsx"
        save_data_to_excel(df_data, df_hourly, df_weekly, df_monthly, excel_file)
        print(f"  âœ… {name}æ•°æ®ä¿å­˜å®Œæˆ: {excel_file}")
        return True
    else:
        print(f"  âŒ {name}æ•°æ®ä¸ºç©ºï¼Œæ— æ³•å¤„ç†")
        return False

# ================= ä¸»å‡½æ•° =================

def load_indices_from_csv(csv_file="indices.csv"):
    """ä»CSVæ–‡ä»¶åŠ è½½æŒ‡æ•°åˆ—è¡¨"""
    try:
        if not os.path.exists(csv_file):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æŒ‡æ•°é…ç½®æ–‡ä»¶ {csv_file}")
            print("è¯·ç¡®ä¿ indices.csv æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«æ­£ç¡®çš„æŒ‡æ•°ä¿¡æ¯")
            return []
        
        df = pd.read_csv(csv_file, encoding='utf-8')
        print(f"ä» {csv_file} åŠ è½½äº† {len(df)} ä¸ªæŒ‡æ•°")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        indexes = []
        for _, row in df.iterrows():
            indexes.append({
                'code': row['code'],
                'name': row['name'],
                'source': row['source'],
                'description': row.get('description', '')
            })
        
        return indexes
    except Exception as e:
        print(f"è¯»å–æŒ‡æ•°é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return []

def main():
    """ä¸»å‡½æ•°ï¼šå‡†å¤‡æŒ‡æ•°æ•°æ®"""
    # å‡†å¤‡æŒ‡æ•°æ•°æ®
    print("å¼€å§‹å‡†å¤‡æŒ‡æ•°æ•°æ®...")
    
    # ä»CSVæ–‡ä»¶åŠ è½½æŒ‡æ•°åˆ—è¡¨
    indexes = load_indices_from_csv()
    
    if not indexes:
        print("æœªèƒ½åŠ è½½æŒ‡æ•°åˆ—è¡¨ï¼Œç¨‹åºé€€å‡º")
        return
    
    # æ˜¾ç¤ºå°†è¦å¤„ç†çš„æŒ‡æ•°
    print(f"\nå°†è¦å¤„ç†ä»¥ä¸‹ {len(indexes)} ä¸ªæŒ‡æ•°ï¼š")
    for i, index in enumerate(indexes, 1):
        desc = index.get('description', '')
        print(f"  {i}. {index['name']} ({index['code']}) - {desc}")
    
    # å‡†å¤‡æŒ‡æ•°æ•°æ®
    index_files = []
    for idx, index in enumerate(indexes):
        print(f"\n[{idx+1}/{len(indexes)}] å¤„ç†æŒ‡æ•° {index['name']}({index['code']})")
        excel_file = fetch_index_data(index['code'], index['name'], index['source'])
        if excel_file:
            print(f"  æŒ‡æ•°æ•°æ®å·²ä¿å­˜åˆ°: {excel_file}")
            index_files.append(excel_file)
        else:
            print(f"  {index['name']}æ•°æ®è·å–å¤±è´¥")
    
    print(f"\næŒ‡æ•°æ•°æ®å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {len(index_files)} ä¸ªæŒ‡æ•°")

if __name__ == "__main__":
    main()
