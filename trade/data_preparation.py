#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import io
import locale
import os
import time
import warnings
import numpy as np
import pandas as pd
import akshare as ak
from datetime import datetime, timedelta
import xlsxwriter
import traceback
import json
import threading
import random

# å¯¼å…¥é…ç½®æ–‡ä»¶
from config import START_DATE, HOURLY_DATA_YEARS

# åŠ è½½æŠ€æœ¯æŒ‡æ ‡å‚æ•°é…ç½®
def load_technical_indicators_config():
    """ä»CSVæ–‡ä»¶åŠ è½½æŠ€æœ¯æŒ‡æ ‡å‚æ•°é…ç½®"""
    config_file = "technical_indicators_config.csv"
    
    if not os.path.exists(config_file):
        print(f"è­¦å‘Šï¼šé…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        return {}
    
    try:
        df_config = pd.read_csv(config_file, encoding='utf-8-sig')
        config_dict = {}
        
        for _, row in df_config.iterrows():
            indicator = row['æŒ‡æ ‡åç§°']
            param_name = row['å‚æ•°åç§°']
            param_value = row['å‚æ•°å€¼']
            
            # å¤„ç†ç‰¹æ®Šæ ¼å¼çš„å‚æ•°å€¼
            if param_name == 'periods' and param_value.startswith('['):
                # è§£æåˆ—è¡¨æ ¼å¼çš„å‚æ•°
                import ast
                param_value = ast.literal_eval(param_value)
            else:
                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                try:
                    param_value = float(param_value)
                    if param_value.is_integer():
                        param_value = int(param_value)
                except ValueError:
                    pass  # ä¿æŒå­—ç¬¦ä¸²æ ¼å¼
            
            if indicator not in config_dict:
                config_dict[indicator] = {}
            config_dict[indicator][param_name] = param_value
        
        print(f"æˆåŠŸåŠ è½½æŠ€æœ¯æŒ‡æ ‡é…ç½®: {config_file}")
        return config_dict
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

# å…¨å±€é…ç½®å˜é‡
TECH_CONFIG = load_technical_indicators_config()

# è§£å†³ä¸­æ–‡ç¼–ç é—®é¢˜
if sys.platform.startswith('win'):
    if sys.getdefaultencoding() != 'utf-8':
        import importlib
        importlib.reload(sys)
    if isinstance(sys.stdout, io.TextIOWrapper):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    if isinstance(sys.stderr, io.TextIOWrapper):
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    try:
        locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
    except:
        locale.setlocale(locale.LC_ALL, '')
        
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LANG'] = 'zh_CN.UTF-8'
os.environ['LC_ALL'] = 'zh_CN.UTF-8'

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# æŒ‡æ ‡è®¡ç®—å‡½æ•°
def calculate_macd(df, fast=None, slow=None, signal=None):
    """è®¡ç®—MACDæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if fast is None:
        fast = TECH_CONFIG.get('MACD', {}).get('fast', 12)
    if slow is None:
        slow = TECH_CONFIG.get('MACD', {}).get('slow', 26)
    if signal is None:
        signal = TECH_CONFIG.get('MACD', {}).get('signal', 9)
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    df['EMA_fast'] = df['close'].ewm(span=fast, adjust=False).mean()
    df['EMA_slow'] = df['close'].ewm(span=slow, adjust=False).mean()
    df['DIF'] = df['EMA_fast'] - df['EMA_slow']
    df['DEA'] = df['DIF'].ewm(span=signal, adjust=False).mean()
    df['MACD'] = (df['DIF'] - df['DEA']) * 2
    return df

def calculate_kdj(df, n=None, m1=None, m2=None):
    """è®¡ç®—KDJæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if n is None:
        n = TECH_CONFIG.get('KDJ', {}).get('n', 9)
    if m1 is None:
        m1 = TECH_CONFIG.get('KDJ', {}).get('m1', 3)
    if m2 is None:
        m2 = TECH_CONFIG.get('KDJ', {}).get('m2', 3)
    
    df = df.copy()
    
    # ç¡®ä¿è¾“å…¥çš„æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['high', 'low', 'close']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # è®¡ç®—æœ€ä½ä»·å’Œæœ€é«˜ä»·
    low_min = df['low'].rolling(window=n, min_periods=1).min()
    high_max = df['high'].rolling(window=n, min_periods=1).max()
    
    # è®¡ç®—RSV
    rsv = (df['close'] - low_min) / (high_max - low_min + 1e-9) * 100
    
    # ä½¿ç”¨ewmè®¡ç®—Kå’ŒDå€¼
    df['K'] = rsv.ewm(alpha=1/m1, adjust=False).mean()
    df['D'] = df['K'].ewm(alpha=1/m2, adjust=False).mean()
    df['J'] = 3 * df['K'] - 2 * df['D']
    return df

def calculate_rsi(df, periods=None):
    """è®¡ç®—RSIæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if periods is None:
        periods = TECH_CONFIG.get('RSI', {}).get('periods', 14)
    
    df = df.copy()
    
    # ç¡®ä¿è¾“å…¥çš„æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    if 'close' in df.columns:
        df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    # è®¡ç®—ä»·æ ¼å˜åŒ–
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # ä½¿ç”¨ewmè®¡ç®—å¹³å‡å¢ç›Šå’ŒæŸå¤±
    avg_gain = gain.ewm(alpha=1/periods, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/periods, adjust=False).mean()
    
    # è®¡ç®—RSå’ŒRSI
    rs = avg_gain / (avg_loss + 1e-9)
    df[f'RSI_{periods}'] = 100 - (100 / (1 + rs))
    
    # ç¡®ä¿æ²¡æœ‰NaNæˆ–æ— ç©·å¤§å€¼
    df[f'RSI_{periods}'] = df[f'RSI_{periods}'].replace([np.inf, -np.inf], np.nan)
    df[f'RSI_{periods}'] = df[f'RSI_{periods}'].ffill().bfill().fillna(50)
    return df

def calculate_boll(df, window=None, std_multiplier=None):
    """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if window is None:
        window = TECH_CONFIG.get('BOLL', {}).get('window', 20)
    if std_multiplier is None:
        std_multiplier = TECH_CONFIG.get('BOLL', {}).get('std_multiplier', 2)
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    df[f'MA{window}'] = df['close'].rolling(window=window).mean()
    df[f'STD{window}'] = df['close'].rolling(window=window).std()
    df['BOLL_UPPER'] = df[f'MA{window}'] + std_multiplier * df[f'STD{window}']
    df['BOLL_LOWER'] = df[f'MA{window}'] - std_multiplier * df[f'STD{window}']
    return df

def calculate_ma(df, periods=None):
    """è®¡ç®—ç§»åŠ¨å¹³å‡çº¿"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if periods is None:
        periods = TECH_CONFIG.get('MA', {}).get('periods', [5, 10, 20, 30, 60])
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    for period in periods:
        df[f'MA{period}'] = df['close'].rolling(window=period).mean()
    return df

def calculate_ema(df, periods=None):
    """è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if periods is None:
        periods = TECH_CONFIG.get('EMA', {}).get('periods', [10, 52])
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    for period in periods:
        df[f'EMA{period}'] = df['close'].ewm(span=period, adjust=False).mean()
    return df

def calculate_atr(df, period=14):
    """è®¡ç®—ATR (Average True Range)"""
    df = df.copy()
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['high', 'low', 'close']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # è®¡ç®—True Range
    high_low = df['high'] - df['low']
    high_close = np.abs(df['high'] - df['close'].shift())
    low_close = np.abs(df['low'] - df['close'].shift())
    
    # å¯¹äºç¬¬ä¸€è¡Œï¼Œhigh_closeå’Œlow_closeä¼šæ˜¯NaNï¼Œæˆ‘ä»¬ç”¨high_lowä»£æ›¿
    true_range = np.maximum(high_low, np.maximum(high_close, low_close))
    
    # å¯¹ç¬¬ä¸€è¡Œï¼Œå¦‚æœæ˜¯NaNï¼Œç”¨high_lowå¡«å……
    true_range.iloc[0] = high_low.iloc[0] if pd.isna(true_range.iloc[0]) else true_range.iloc[0]
    
    # è®¡ç®—ATRï¼Œä¿æŒç´¢å¼•ä¸€è‡´
    atr = pd.Series(true_range, index=df.index).rolling(window=period, min_periods=1).mean()
    
    return atr

def calculate_trend_indicator_a(df, ma_period=None, ma_type=None):
    """è®¡ç®—Trend Indicator A-V2 (Smoothed Heikin Ashi Cloud)"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if ma_period is None:
        ma_period = TECH_CONFIG.get('TREND_A', {}).get('ma_period', 9)  # ä¿®æ­£é»˜è®¤å€¼ä¸º9
    if ma_type is None:
        ma_type = TECH_CONFIG.get('TREND_A', {}).get('ma_type', 'EMA')
    
    df = df.copy()
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = ['open', 'high', 'low', 'close']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"  è­¦å‘Šï¼šTrend Indicator Aè®¡ç®—ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        print(f"  å½“å‰å¯ç”¨åˆ—: {list(df.columns)}")
        # è¿”å›ç©ºçš„TrendAåˆ—
        df['TREND_A_OPEN'] = np.nan
        df['TREND_A_CLOSE'] = np.nan
        df['TREND_A_HIGH'] = np.nan
        df['TREND_A_LOW'] = np.nan
        df['TREND_A_STRENGTH'] = np.nan
        df['TREND_A_DIRECTION'] = np.nan
        return df
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['open', 'high', 'low', 'close']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ•°å€¼æ•°æ®
    if df[['open', 'high', 'low', 'close']].isnull().all().any():
        print(f"  è­¦å‘Šï¼šTrend Indicator Aè®¡ç®—é‡åˆ°å…¨ç©ºæ•°æ®")
        df['TREND_A_OPEN'] = np.nan
        df['TREND_A_CLOSE'] = np.nan
        df['TREND_A_HIGH'] = np.nan
        df['TREND_A_LOW'] = np.nan
        df['TREND_A_STRENGTH'] = np.nan
        df['TREND_A_DIRECTION'] = np.nan
        return df
    
    # è®¡ç®—Heikin Ashi
    ha_close = (df['open'] + df['high'] + df['low'] + df['close']) / 4
    ha_open = pd.Series(index=df.index, dtype=float)
    ha_open.iloc[0] = (df['open'].iloc[0] + df['close'].iloc[0]) / 2
    
    for i in range(1, len(df)):
        ha_open.iloc[i] = (ha_open.iloc[i-1] + ha_close.iloc[i-1]) / 2
    
    ha_high = pd.concat([df['high'], ha_open, ha_close], axis=1).max(axis=1)
    ha_low = pd.concat([df['low'], ha_open, ha_close], axis=1).min(axis=1)
    
    # æ ¹æ®2024å¹´4æœˆ23æ—¥æ›´æ–°ï¼Œç§»é™¤åŒé‡å¹³æ»‘ï¼Œåªä½¿ç”¨å•çº§EMAå¹³æ»‘
    if ma_type == 'EMA':
        # åªä½¿ç”¨å•çº§EMAå¹³æ»‘ï¼Œå‡å°‘å»¶è¿Ÿ
        df['TREND_A_OPEN'] = ha_open.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_CLOSE'] = ha_close.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_HIGH'] = ha_high.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_LOW'] = ha_low.ewm(span=ma_period, adjust=False).mean()
    elif ma_type == 'SMA':
        # åªä½¿ç”¨å•çº§SMAå¹³æ»‘
        df['TREND_A_OPEN'] = ha_open.rolling(window=ma_period, min_periods=1).mean()
        df['TREND_A_CLOSE'] = ha_close.rolling(window=ma_period, min_periods=1).mean()
        df['TREND_A_HIGH'] = ha_high.rolling(window=ma_period, min_periods=1).mean()
        df['TREND_A_LOW'] = ha_low.rolling(window=ma_period, min_periods=1).mean()
    else:  # é»˜è®¤ä½¿ç”¨EMA
        # åªä½¿ç”¨å•çº§EMAå¹³æ»‘
        df['TREND_A_OPEN'] = ha_open.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_CLOSE'] = ha_close.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_HIGH'] = ha_high.ewm(span=ma_period, adjust=False).mean()
        df['TREND_A_LOW'] = ha_low.ewm(span=ma_period, adjust=False).mean()
    
    # è®¡ç®—è¶‹åŠ¿å¼ºåº¦ - æ ¹æ®åŸå§‹PineScripté€»è¾‘
    df['TREND_A_STRENGTH'] = 100 * (df['TREND_A_CLOSE'] - df['TREND_A_OPEN']) / (df['TREND_A_HIGH'] - df['TREND_A_LOW'] + 1e-9)
    
    # è¶‹åŠ¿æ–¹å‘ - æ ¹æ®åŸå§‹PineScripté€»è¾‘ï¼štrend > 0 ä¸ºçœ‹æ¶¨ï¼Œtrend < 0 ä¸ºçœ‹è·Œ
    df['TREND_A_DIRECTION'] = np.where(df['TREND_A_STRENGTH'] > 0, 1, -1)
    
    return df

def calculate_supertrend(df, atr_length=None, multiplier=None):
    """è®¡ç®—SuperTrendæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°
    if atr_length is None:
        atr_length = TECH_CONFIG.get('SUPERTREND', {}).get('atr_length', 10)
    if multiplier is None:
        multiplier = TECH_CONFIG.get('SUPERTREND', {}).get('multiplier', 3.0)
    
    df = df.copy()
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = ['high', 'low', 'close']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"  è­¦å‘Šï¼šSuperTrendè®¡ç®—ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        print(f"  å½“å‰å¯ç”¨åˆ—: {list(df.columns)}")
        # è¿”å›ç©ºçš„SuperTrendåˆ—
        df['SUPERTREND'] = np.nan
        df['SUPERTREND_DIRECTION'] = np.nan
        df['SUPERTREND_UPPER'] = np.nan
        df['SUPERTREND_LOWER'] = np.nan
        return df
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in ['high', 'low', 'close']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ•°å€¼æ•°æ®
    if df[['high', 'low', 'close']].isnull().all().any():
        print(f"  è­¦å‘Šï¼šSuperTrendè®¡ç®—é‡åˆ°å…¨ç©ºæ•°æ®")
        df['SUPERTREND'] = np.nan
        df['SUPERTREND_DIRECTION'] = np.nan
        df['SUPERTREND_UPPER'] = np.nan
        df['SUPERTREND_LOWER'] = np.nan
        return df
    
    # è®¡ç®—ATR
    atr = calculate_atr(df, atr_length)
    
    # è®¡ç®—HL2
    hl2 = (df['high'] + df['low']) / 2
    
    # è®¡ç®—åŸºç¡€ä¸Šä¸‹è½¨
    basic_upper_band = hl2 + (multiplier * atr)
    basic_lower_band = hl2 - (multiplier * atr)
    
    # åˆå§‹åŒ–æœ€ç»ˆä¸Šä¸‹è½¨
    upper_band = pd.Series(index=df.index, dtype=float)
    lower_band = pd.Series(index=df.index, dtype=float)
    
    upper_band.iloc[0] = basic_upper_band.iloc[0]
    lower_band.iloc[0] = basic_lower_band.iloc[0]
    
    # è®¡ç®—æœ€ç»ˆä¸Šä¸‹è½¨
    for i in range(1, len(df)):
        # ä¸Šè½¨è®¡ç®—
        if basic_upper_band.iloc[i] < upper_band.iloc[i-1] or df['close'].iloc[i-1] > upper_band.iloc[i-1]:
            upper_band.iloc[i] = basic_upper_band.iloc[i]
        else:
            upper_band.iloc[i] = upper_band.iloc[i-1]
        
        # ä¸‹è½¨è®¡ç®—
        if basic_lower_band.iloc[i] > lower_band.iloc[i-1] or df['close'].iloc[i-1] < lower_band.iloc[i-1]:
            lower_band.iloc[i] = basic_lower_band.iloc[i]
        else:
            lower_band.iloc[i] = lower_band.iloc[i-1]
    
    # è®¡ç®—SuperTrend
    supertrend = pd.Series(index=df.index, dtype=float)
    trend_direction = pd.Series(index=df.index, dtype=int)
    
    # åˆå§‹åŒ– - åœ¨ATRè®¡ç®—å®Œæˆä¹‹å‰ï¼Œè¶‹åŠ¿æ–¹å‘é»˜è®¤ä¸ºä¸‹é™è¶‹åŠ¿
    trend_direction.iloc[0] = -1  # ä¸‹é™è¶‹åŠ¿
    supertrend.iloc[0] = upper_band.iloc[0]
    
    for i in range(1, len(df)):
        # æ ¹æ®SuperTrend.txtçš„æ ‡å‡†é€»è¾‘
        if supertrend.iloc[i-1] == upper_band.iloc[i-1]:
            # å‰ä¸€ä¸ªSuperTrendç­‰äºå‰ä¸€ä¸ªä¸Šè½¨ï¼Œæ£€æŸ¥å½“å‰æ”¶ç›˜ä»·æ˜¯å¦çªç ´ä¸Šè½¨
            if df['close'].iloc[i] > upper_band.iloc[i]:
                trend_direction.iloc[i] = 1  # è½¬ä¸ºä¸Šå‡è¶‹åŠ¿
                supertrend.iloc[i] = lower_band.iloc[i]
            else:
                trend_direction.iloc[i] = -1  # ä¿æŒä¸‹é™è¶‹åŠ¿
                supertrend.iloc[i] = upper_band.iloc[i]
        else:
            # å‰ä¸€ä¸ªSuperTrendç­‰äºå‰ä¸€ä¸ªä¸‹è½¨ï¼Œæ£€æŸ¥å½“å‰æ”¶ç›˜ä»·æ˜¯å¦çªç ´ä¸‹è½¨
            if df['close'].iloc[i] < lower_band.iloc[i]:
                trend_direction.iloc[i] = -1  # è½¬ä¸ºä¸‹é™è¶‹åŠ¿
                supertrend.iloc[i] = upper_band.iloc[i]
            else:
                trend_direction.iloc[i] = 1  # ä¿æŒä¸Šå‡è¶‹åŠ¿
                supertrend.iloc[i] = lower_band.iloc[i]
    
    df['SUPERTREND'] = supertrend
    df['SUPERTREND_DIRECTION'] = trend_direction
    df['SUPERTREND_UPPER'] = upper_band
    df['SUPERTREND_LOWER'] = lower_band
    
    return df

def calculate_qqe_mod(df, 
                     rsi_length_primary=None, rsi_smoothing_primary=None, qqe_factor_primary=None, threshold_primary=None,
                     rsi_length_secondary=None, rsi_smoothing_secondary=None, qqe_factor_secondary=None, threshold_secondary=None,
                     bollinger_length=None, bollinger_multiplier=None):
    """è®¡ç®—QQE MODæŒ‡æ ‡"""
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°
    config = TECH_CONFIG.get('QQEMOD', {})
    if rsi_length_primary is None:
        rsi_length_primary = config.get('rsi_length_primary', 6)
    if rsi_smoothing_primary is None:
        rsi_smoothing_primary = config.get('rsi_smoothing_primary', 5)
    if qqe_factor_primary is None:
        qqe_factor_primary = config.get('qqe_factor_primary', 3.0)
    if threshold_primary is None:
        threshold_primary = config.get('threshold_primary', 3.0)
    if rsi_length_secondary is None:
        rsi_length_secondary = config.get('rsi_length_secondary', 6)
    if rsi_smoothing_secondary is None:
        rsi_smoothing_secondary = config.get('rsi_smoothing_secondary', 5)
    if qqe_factor_secondary is None:
        qqe_factor_secondary = config.get('qqe_factor_secondary', 1.61)
    if threshold_secondary is None:
        threshold_secondary = config.get('threshold_secondary', 3.0)
    if bollinger_length is None:
        bollinger_length = config.get('bollinger_length', 50)
    if bollinger_multiplier is None:
        bollinger_multiplier = config.get('bollinger_multiplier', 0.35)
    
    df = df.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    def calculate_qqe_bands(source, rsi_length, smoothing_factor, qqe_factor):
        """è®¡ç®—QQE bands"""
        wilders_length = rsi_length * 2 - 1
        
        # è®¡ç®—RSI
        delta = source.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.ewm(alpha=1/rsi_length, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1/rsi_length, adjust=False).mean()
        rs = avg_gain / (avg_loss + 1e-9)
        rsi = 100 - (100 / (1 + rs))
        
        # å¹³æ»‘RSI
        smoothed_rsi = rsi.ewm(span=smoothing_factor, adjust=False).mean()
        
        # è®¡ç®—ATR-likeæŒ‡æ ‡
        atr_rsi = np.abs(smoothed_rsi.diff())
        smoothed_atr_rsi = atr_rsi.ewm(span=wilders_length, adjust=False).mean()
        dynamic_atr_rsi = smoothed_atr_rsi * qqe_factor
        
        # åˆå§‹åŒ–bands
        long_band = pd.Series(index=source.index, dtype=float)
        short_band = pd.Series(index=source.index, dtype=float)
        trend_direction = pd.Series(index=source.index, dtype=int)
        
        # è®¡ç®—ç¬¬ä¸€ä¸ªå€¼
        long_band.iloc[0] = smoothed_rsi.iloc[0] - dynamic_atr_rsi.iloc[0]
        short_band.iloc[0] = smoothed_rsi.iloc[0] + dynamic_atr_rsi.iloc[0]
        trend_direction.iloc[0] = 1
        
        for i in range(1, len(source)):
            new_long_band = smoothed_rsi.iloc[i] - dynamic_atr_rsi.iloc[i]
            new_short_band = smoothed_rsi.iloc[i] + dynamic_atr_rsi.iloc[i]
            
            # æ›´æ–°long_band
            if smoothed_rsi.iloc[i-1] > long_band.iloc[i-1] and smoothed_rsi.iloc[i] > long_band.iloc[i-1]:
                long_band.iloc[i] = max(long_band.iloc[i-1], new_long_band)
            else:
                long_band.iloc[i] = new_long_band
            
            # æ›´æ–°short_band
            if smoothed_rsi.iloc[i-1] < short_band.iloc[i-1] and smoothed_rsi.iloc[i] < short_band.iloc[i-1]:
                short_band.iloc[i] = min(short_band.iloc[i-1], new_short_band)
            else:
                short_band.iloc[i] = new_short_band
            
            # æ›´æ–°è¶‹åŠ¿æ–¹å‘
            if smoothed_rsi.iloc[i] > short_band.iloc[i-1]:
                trend_direction.iloc[i] = 1
            elif smoothed_rsi.iloc[i] < long_band.iloc[i-1]:
                trend_direction.iloc[i] = -1
            else:
                trend_direction.iloc[i] = trend_direction.iloc[i-1]
        
        # ç¡®å®šè¶‹åŠ¿çº¿
        qqe_trend_line = pd.Series(index=source.index, dtype=float)
        for i in range(len(source)):
            qqe_trend_line.iloc[i] = long_band.iloc[i] if trend_direction.iloc[i] == 1 else short_band.iloc[i]
        
        return qqe_trend_line, smoothed_rsi
    
    # è®¡ç®—ä¸»QQE
    primary_qqe_trend, primary_rsi = calculate_qqe_bands(
        df['close'], rsi_length_primary, rsi_smoothing_primary, qqe_factor_primary
    )
    
    # è®¡ç®—å‰¯QQE
    secondary_qqe_trend, secondary_rsi = calculate_qqe_bands(
        df['close'], rsi_length_secondary, rsi_smoothing_secondary, qqe_factor_secondary
    )
    
    # è®¡ç®—å¸ƒæ—å¸¦
    bollinger_basis = (primary_qqe_trend - 50).rolling(window=bollinger_length, min_periods=1).mean()
    bollinger_deviation = bollinger_multiplier * (primary_qqe_trend - 50).rolling(window=bollinger_length, min_periods=1).std()
    bollinger_upper = bollinger_basis + bollinger_deviation
    bollinger_lower = bollinger_basis - bollinger_deviation
    
    # å­˜å‚¨ç»“æœ
    df['QQE_PRIMARY_TREND'] = primary_qqe_trend
    df['QQE_PRIMARY_RSI'] = primary_rsi
    df['QQE_SECONDARY_TREND'] = secondary_qqe_trend
    df['QQE_SECONDARY_RSI'] = secondary_rsi
    df['QQE_BOLLINGER_UPPER'] = bollinger_upper
    df['QQE_BOLLINGER_LOWER'] = bollinger_lower
    df['QQE_BOLLINGER_BASIS'] = bollinger_basis
    
    # è®¡ç®—ä¿¡å·
    df['QQE_UP_SIGNAL'] = np.where(
        (secondary_rsi - 50 > threshold_secondary) & (primary_rsi - 50 > bollinger_upper), 1, 0
    )
    df['QQE_DOWN_SIGNAL'] = np.where(
        (secondary_rsi - 50 < -threshold_secondary) & (primary_rsi - 50 < bollinger_lower), 1, 0
    )
    
    return df

def generate_weekly_view(df):
    """ç”Ÿæˆæ­£ç¡®çš„å‘¨çº¿è§†å›¾"""
    # åˆ›å»ºæ•°æ®å‰¯æœ¬
    df_copy = df.copy()
    
    # ç¡®ä¿æœ‰æœ‰æ•ˆçš„æ—¥æœŸåˆ—
    if 'date' not in df_copy.columns:
        df_copy['date'] = pd.to_datetime(df_copy.index)
    
    # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•
    df_copy = df_copy.set_index('date')
    
    # æŒ‰å‘¨åˆ†ç»„ï¼ˆæ¯å‘¨ä»å‘¨ä¸€å¼€å§‹ï¼Œå‘¨äº”ç»“æŸï¼‰
    agg_dict = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }
    # å¦‚æœå­˜åœ¨æˆäº¤é¢åˆ—ï¼Œåˆ™èšåˆæˆäº¤é¢ï¼ˆæ±‚å’Œï¼‰
    if 'amount' in df_copy.columns:
        agg_dict['amount'] = 'sum'
    weekly = df_copy.resample('W-FRI').agg(agg_dict)
    
    # åˆ é™¤ç©ºè¡Œ
    weekly = weekly.dropna()
    
    # é‡ç½®ç´¢å¼•å¹¶å°†æ—¥æœŸåˆ—å‘½åä¸º'date'
    weekly = weekly.reset_index()
    weekly = weekly.rename(columns={'date': 'date'})
    return weekly

def generate_monthly_view(df):
    """ç”Ÿæˆæ­£ç¡®çš„æœˆçº¿è§†å›¾"""
    # åˆ›å»ºæ•°æ®å‰¯æœ¬
    df_copy = df.copy()
    
    # ç¡®ä¿æœ‰æœ‰æ•ˆçš„æ—¥æœŸåˆ—
    if 'date' not in df_copy.columns:
        df_copy['date'] = pd.to_datetime(df_copy.index)
    
    # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•
    df_copy = df_copy.set_index('date')
    
    # æŒ‰æœˆåˆ†ç»„
    agg_dict = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }
    # å¦‚æœå­˜åœ¨æˆäº¤é¢åˆ—ï¼Œåˆ™èšåˆæˆäº¤é¢ï¼ˆæ±‚å’Œï¼‰
    if 'amount' in df_copy.columns:
        agg_dict['amount'] = 'sum'
    monthly = df_copy.resample('ME').agg(agg_dict)
    
    # åˆ é™¤ç©ºè¡Œ
    monthly = monthly.dropna()
    
    # é‡ç½®ç´¢å¼•å¹¶å°†æ—¥æœŸåˆ—å‘½åä¸º'date'
    monthly = monthly.reset_index()
    monthly = monthly.rename(columns={'date': 'date'})
    return monthly

def fetch_stock_data_hourly_china(stock_code, max_retries=3, base_delay=1):
    """ä½¿ç”¨å›½å†…æ•°æ®æºè·å–è‚¡ç¥¨å°æ—¶çº¿æ•°æ®"""
    for attempt in range(max_retries):
        try:
            print(f"  ä½¿ç”¨å›½å†…æ•°æ®æºè·å–è‚¡ç¥¨å°æ—¶çº¿æ•°æ®({stock_code})... å°è¯• {attempt + 1}/{max_retries}")
            
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            if attempt > 0:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 0.5)
                print(f"  ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            
            # å°è¯•è·å–åˆ†é’Ÿæ•°æ®ç„¶åèšåˆä¸ºå°æ—¶çº¿
            df_hourly = pd.DataFrame()
            
            # ä½¿ç”¨ stock_zh_a_hist_min_em æ¥å£è·å–å°æ—¶çº¿æ•°æ®ï¼ˆperiod="60"è¡¨ç¤º60åˆ†é’Ÿï¼‰
            # æ³¨æ„ï¼šè¯¥æ¥å£åªèƒ½è¿”å›è¿‘æœŸæ•°æ®ï¼Œä¸èƒ½è¿”å›æ‰€æœ‰å†å²æ•°æ®
            stock_code_clean = stock_code[2:] if stock_code.startswith(('sh', 'sz')) else stock_code
            
            # è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆå°è¯•è·å–æœ€è¿‘Nå¹´çš„æ•°æ®ï¼Œé€æ­¥å›é€€ï¼‰
            end_date = datetime.now()
            max_days = HOURLY_DATA_YEARS * 365  # é…ç½®çš„å¹´æ•°è½¬æ¢ä¸ºå¤©æ•°
            
            # å°è¯•å¤šä¸ªæ—¶é—´èŒƒå›´ï¼Œä»æœ€é•¿åˆ°æœ€çŸ­
            time_ranges = [
                max_days,      # é…ç½®çš„å¹´æ•°
                int(max_days * 0.75),  # 75%
                int(max_days * 0.5),   # 50%
                int(max_days * 0.25),  # 25%
                90,            # 3ä¸ªæœˆ
                30,            # 1ä¸ªæœˆ
            ]
            
            df_minute = pd.DataFrame()
            for days in time_ranges:
                try:
                    start_date = end_date - timedelta(days=days)
                    start_date_str = start_date.strftime("%Y-%m-%d 09:30:00")
                    end_date_str = end_date.strftime("%Y-%m-%d 15:00:00")
                    
                    print(f"    å°è¯•è·å–æœ€è¿‘ {days} å¤©çš„å°æ—¶çº¿æ•°æ®...")
                    # ä½¿ç”¨ stock_zh_a_hist_min_em è·å–60åˆ†é’Ÿæ•°æ®
                    # å…ˆå°è¯•å¸¦å‰å¤æƒå‚æ•°
                    try:
                        df_minute = ak.stock_zh_a_hist_min_em(
                            symbol=stock_code_clean, 
                            period="60", 
                            start_date=start_date_str, 
                            end_date=end_date_str,
                            adjust="qfq"  # å‰å¤æƒ
                        )
                    except:
                        # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä¸å¸¦adjustå‚æ•°
                        try:
                            df_minute = ak.stock_zh_a_hist_min_em(
                                symbol=stock_code_clean, 
                                period="60", 
                                start_date=start_date_str, 
                                end_date=end_date_str
                            )
                        except Exception as e2:
                            print(f"    âš ï¸  APIè°ƒç”¨å¤±è´¥: {str(e2)[:50]}")
                            continue
                    
                    if not df_minute.empty:
                        df_hourly = df_minute.copy()
                        print(f"    âœ… æˆåŠŸè·å–å°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
                        break
                except Exception as e:
                    print(f"    âš ï¸  è·å–æœ€è¿‘ {days} å¤©æ•°æ®å¤±è´¥: {str(e)[:50]}")
                    continue
            
            if df_minute.empty:
                print(f"    âŒ æ‰€æœ‰æ—¶é—´èŒƒå›´éƒ½å¤±è´¥ï¼Œå°†ä½¿ç”¨æ—¥çº¿æ•°æ®ç”Ÿæˆå°æ—¶çº¿")
            
            if not df_hourly.empty:
                # ç»Ÿä¸€æ•°æ®æ ¼å¼ - stock_zh_a_hist_min_em è¿”å›çš„åˆ—åæ˜¯ä¸­æ–‡
                column_mapping = {
                    'æ—¶é—´': 'date',
                    'å¼€ç›˜': 'open',
                    'æ”¶ç›˜': 'close',
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'æˆäº¤é‡': 'volume',
                    'æˆäº¤é¢': 'amount',
                    'å‡ä»·': 'average'
                }
                
                # æ£€æŸ¥å¹¶åº”ç”¨åˆ—åæ˜ å°„
                available_mapping = {k: v for k, v in column_mapping.items() if k in df_hourly.columns}
                if available_mapping:
                    df_hourly = df_hourly.rename(columns=available_mapping)
                
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                required_cols = ['date', 'open', 'high', 'low', 'close']
                if all(col in df_hourly.columns for col in required_cols):
                    print(f"  æˆåŠŸè·å–å°æ—¶çº¿æ•°æ®ï¼Œå…± {len(df_hourly)} è¡Œ")
                    return df_hourly
                else:
                    missing_cols = [col for col in required_cols if col not in df_hourly.columns]
                    print(f"  å°æ—¶çº¿æ•°æ®æ ¼å¼ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                    print(f"  å½“å‰å¯ç”¨åˆ—: {list(df_hourly.columns)}")
            else:
                print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼šå°æ—¶çº¿æ•°æ®ä¸ºç©º")
                
        except Exception as e:
            error_msg = str(e)
            print(f"  å°è¯• {attempt + 1} å¤±è´¥ï¼š{error_msg}")
            
            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
            if attempt == max_retries - 1:
                print(f"  æ‰€æœ‰ {max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
                return None
    
    return None

def generate_hourly_view(df):
    """ç”Ÿæˆå°æ—¶çº¿æ•°æ®ï¼ˆä»æ—¥çº¿æ•°æ®ç”Ÿæˆï¼Œæ¯ä¸ªäº¤æ˜“æ—¥æŒ‰å°æ—¶åˆ†ç»„ï¼‰- ä»…ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼Œä¼˜å…ˆä½¿ç”¨APIæ‹‰å–"""
    if df.empty:
        return pd.DataFrame()
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # ç”±äºæ—¥çº¿æ•°æ®æ²¡æœ‰å°æ—¶ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆå°æ—¶çº¿æ•°æ®
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æ—¥çº¿æ•°æ®ï¼Œä½†æ ‡è®°ä¸ºå°æ—¶çº¿ï¼ˆå®é™…æ˜¯æ—¥çº¿æ•°æ®çš„å¤åˆ¶ï¼‰
    # å¦‚æœéœ€è¦çœŸæ­£çš„å°æ—¶çº¿æ•°æ®ï¼Œéœ€è¦ä»åˆ†é’Ÿæ•°æ®èšåˆ
    # æ³¨æ„ï¼šæ­¤å‡½æ•°ä»…ä½œä¸ºæ— æ³•ä»APIæ‹‰å–å°æ—¶çº¿æ•°æ®æ—¶çš„åå¤‡æ–¹æ¡ˆ
    hourly = df.copy()
    
    # ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆ4ä¸ªå°æ—¶çº¿æ•°æ®ç‚¹ï¼ˆ9:30, 10:30, 13:00, 14:00ï¼‰
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨æ—¥çº¿æ•°æ®ä½œä¸ºå°æ—¶çº¿æ•°æ®
    hourly_list = []
    for _, row in df.iterrows():
        date = row['date']
        # ç”Ÿæˆ4ä¸ªå°æ—¶çº¿æ•°æ®ç‚¹
        for hour in [9, 10, 13, 14]:
            hour_date = pd.Timestamp(date.year, date.month, date.day, hour, 30 if hour < 12 else 0)
            hourly_row = row.copy()
            hourly_row['date'] = hour_date
            hourly_list.append(hourly_row)
    
    if hourly_list:
        hourly = pd.DataFrame(hourly_list)
        hourly = hourly.sort_values('date')
    
    return hourly


def get_hs300_stocks():
    """ä»CSVæ–‡ä»¶è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨"""
    csv_file = "hs300_stocks.csv"
    
    # å¦‚æœCSVæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå¹¶ä½¿ç”¨é»˜è®¤åˆ—è¡¨
    if not os.path.exists(csv_file):
        print(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}ï¼Œå°†ä½¿ç”¨é¢„å®šä¹‰è‚¡ç¥¨åˆ—è¡¨å¹¶åˆ›å»ºCSVæ–‡ä»¶")
        
        # é¢„å®šä¹‰è‚¡ç¥¨åˆ—è¡¨
        default_stocks = [
            ('sh600519', 'è´µå·èŒ…å°'), ('sz000001', 'å¹³å®‰é“¶è¡Œ'), ('sh601398', 'å·¥å•†é“¶è¡Œ'),
            ('sh600036', 'æ‹›å•†é“¶è¡Œ'), ('sz000333', 'ç¾çš„é›†å›¢'), ('sh600031', 'ä¸‰ä¸€é‡å·¥'),
            ('sz002415', 'æµ·åº·å¨è§†'), ('sh601088', 'ä¸­å›½ç¥å'), ('sh600585', 'æµ·èºæ°´æ³¥'),
            ('sh601857', 'ä¸­å›½çŸ³æ²¹'), ('sh600690', 'æµ·å°”æ™ºå®¶'), ('sh601818', 'å…‰å¤§é“¶è¡Œ'),
            ('sh600104', 'ä¸Šæ±½é›†å›¢'), ('sz000002', 'ä¸‡ç§‘A'), ('sh601988', 'ä¸­å›½é“¶è¡Œ'),
            ('sh600028', 'ä¸­å›½çŸ³åŒ–'), ('sh601288', 'å†œä¸šé“¶è¡Œ'), ('sh600019', 'å®é’¢è‚¡ä»½'),
            ('sh601328', 'äº¤é€šé“¶è¡Œ'), ('sh601166', 'å…´ä¸šé“¶è¡Œ'), ('sh601939', 'å»ºè®¾é“¶è¡Œ'),
            ('sh600016', 'æ°‘ç”Ÿé“¶è¡Œ'), ('sh600000', 'æµ¦å‘é“¶è¡Œ'), ('sh601998', 'ä¸­ä¿¡é“¶è¡Œ'),
            ('sh601169', 'åŒ—äº¬é“¶è¡Œ'), ('sh601229', 'ä¸Šæµ·é“¶è¡Œ'), ('sz300085', 'é“¶ä¹‹æ°')
        ]
        
        # åˆ›å»ºCSVæ–‡ä»¶
        df = pd.DataFrame(default_stocks, columns=['symbol', 'name'])
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')  # ä½¿ç”¨å¸¦BOMçš„UTF-8
        print(f"å·²åˆ›å»ºCSVæ–‡ä»¶: {csv_file}")
        
        return default_stocks
    
    try:
        # å°è¯•å¤šç§ç¼–ç è¯»å–CSVæ–‡ä»¶
        encodings = ['utf-8-sig', 'gbk', 'latin1', 'utf-16']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(csv_file, encoding=encoding)
                print(f"ä½¿ç”¨ {encoding} ç¼–ç æˆåŠŸè¯»å–CSVæ–‡ä»¶")
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"å°è¯• {encoding} ç¼–ç æ—¶å‡ºé”™: {e}")
                continue
        
        if df is None:
            raise ValueError("æ— æ³•ä½¿ç”¨ä»»ä½•æ”¯æŒçš„ç¼–ç è¯»å–CSVæ–‡ä»¶")
        
        # ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—
        if 'symbol' not in df.columns or 'name' not in df.columns:
            # å°è¯•è‡ªåŠ¨æ£€æµ‹åˆ—å
            possible_columns = {
                'ä»£ç ': 'symbol', 'è‚¡ç¥¨ä»£ç ': 'symbol', 'è¯åˆ¸ä»£ç ': 'symbol',
                'åç§°': 'name', 'è‚¡ç¥¨åç§°': 'name', 'è¯åˆ¸åç§°': 'name'
            }
            
            for col in df.columns:
                if col in possible_columns:
                    df = df.rename(columns={col: possible_columns[col]})
            
            if 'symbol' not in df.columns or 'name' not in df.columns:
                raise ValueError("CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—ï¼ˆ'symbol'æˆ–'name')")
        
        # è½¬æ¢ä¸ºå…ƒç»„åˆ—è¡¨
        stock_list = list(df[['symbol', 'name']].itertuples(index=False, name=None))
        
        print(f"ä»CSVæ–‡ä»¶è¯»å– {len(stock_list)} åªè‚¡ç¥¨")
        return stock_list
    except Exception as e:
        print(f"è¯»å–è‚¡ç¥¨åˆ—è¡¨CSVæ–‡ä»¶å¤±è´¥: {e}")
        print(traceback.format_exc())
        return []


def save_data_to_excel(df_daily, df_hourly, df_weekly, df_monthly, filename):
    """å°†æ•°æ®ä¿å­˜åˆ°Excelæ–‡ä»¶ï¼ŒåŒ…å«å¤šä¸ªå·¥ä½œè¡¨ï¼ˆçº¯è¡¨æ ¼ï¼Œæ”¯æŒå°æ—¶çº¿ï¼‰"""
    # ç¡®ä¿æ‰€æœ‰æ•°æ®æ¡†éƒ½æœ‰'date'åˆ—
    if 'date' not in df_daily.columns:
        if df_daily.index.name == 'date':
            df_daily = df_daily.reset_index()
        else:
            df_daily['date'] = df_daily.index
    
    if df_hourly is not None and not df_hourly.empty and 'date' not in df_hourly.columns:
        if df_hourly.index.name == 'date':
            df_hourly = df_hourly.reset_index()
        else:
            df_hourly['date'] = df_hourly.index
    
    if df_weekly is not None and 'date' not in df_weekly.columns:
        if df_weekly.index.name == 'date':
            df_weekly = df_weekly.reset_index()
        else:
            df_weekly['date'] = df_weekly.index
    
    if df_monthly is not None and 'date' not in df_monthly.columns:
        if df_monthly.index.name == 'date':
            df_monthly = df_monthly.reset_index()
        else:
            df_monthly['date'] = df_monthly.index
    
    # åˆ›å»ºExcelå†™å…¥å™¨
    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
        # ä¿å­˜æ—¥çº¿æ•°æ®
        df_daily.to_excel(writer, sheet_name='æ—¥çº¿æ•°æ®', index=False)
        
        # ä¿å­˜å°æ—¶çº¿æ•°æ®
        if df_hourly is not None and not df_hourly.empty:
            df_hourly.to_excel(writer, sheet_name='å°æ—¶çº¿æ•°æ®', index=False)
        
        # ä¿å­˜å‘¨çº¿æ•°æ®
        if df_weekly is not None and not df_weekly.empty:
            df_weekly.to_excel(writer, sheet_name='å‘¨çº¿æ•°æ®', index=False)
        
        # ä¿å­˜æœˆçº¿æ•°æ®
        if df_monthly is not None and not df_monthly.empty:
            df_monthly.to_excel(writer, sheet_name='æœˆçº¿æ•°æ®', index=False)
    
    print(f"  æ•°æ®å·²ä¿å­˜åˆ°Excelæ–‡ä»¶: {filename}")

def prepare_stock_data(stock_code, stock_name):
    """å‡†å¤‡è‚¡ç¥¨æ•°æ®å¹¶ä¿å­˜åˆ°Excelæ–‡ä»¶"""
    print(f"  ğŸ“ˆ å¼€å§‹å‡†å¤‡ {stock_name}({stock_code}) çš„æ•°æ®...")
    
    # åˆ›å»ºæ•°æ®ç›®å½•
    if not os.path.exists("stock_data"):
        os.makedirs("stock_data")
        print("  ğŸ“ åˆ›å»ºstock_dataç›®å½•")
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ¸¯è‚¡å’ŒAè‚¡éƒ½å»æ‰å‰2ä¸ªå­—ç¬¦ï¼‰
    excel_file = f"stock_data/{stock_code[2:]}_{stock_name}_æŠ€æœ¯æ•°æ®.xlsx"
    
    # å¦‚æœæ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œåˆ·æ–°æ•°æ®
    if os.path.exists(excel_file):
        file_date = datetime.fromtimestamp(os.path.getmtime(excel_file)).date()
        if file_date == datetime.today().date():
            print(f"  ğŸ”„ åˆ·æ–°æ•°æ®: {excel_file}")
            os.remove(excel_file)  # å¼ºåˆ¶æ¯æ¬¡è¿è¡Œåˆ·æ–°æ•°æ®

    
    # åˆ¤æ–­è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€åŒ—äº¤æ‰€ï¼‰
    is_hk_stock = stock_code.startswith('hk')
    # åŒ—äº¤æ‰€è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šsz430xxx, sz837xxx, sz889xxx, sz43xxxx, sz83xxxx, sz88xxxx
    is_bj_stock = (stock_code.startswith('sz430') or 
                   stock_code.startswith('sz837') or 
                   stock_code.startswith('sz889') or
                   (stock_code.startswith('sz43') and len(stock_code) >= 6) or
                   (stock_code.startswith('sz83') and len(stock_code) >= 6) or
                   (stock_code.startswith('sz88') and len(stock_code) >= 6))
    
    # æ‹‰å–æ•°æ®
    if is_hk_stock:
        # æ¸¯è‚¡ï¼šå»æ‰ 'hk' å‰ç¼€ï¼Œä¿ç•™æ•°å­—ä»£ç ï¼Œå¹¶è¡¥é½å‰å¯¼0åˆ°5ä½
        # ä¾‹å¦‚ï¼šhk2331 -> 02331, hk700 -> 00700
        symbol_code_raw = stock_code[2:]
        # è¡¥é½å‰å¯¼0åˆ°5ä½ï¼ˆæ¸¯è‚¡ä»£ç é€šå¸¸æ˜¯5ä½æ•°å­—ï¼‰
        symbol_code = symbol_code_raw.zfill(5)
    elif is_bj_stock:
        # åŒ—äº¤æ‰€ï¼šå»æ‰ 'sz' å‰ç¼€ï¼Œä¿ç•™æ•°å­—ä»£ç ï¼ˆå¦‚ sz430090 -> 430090ï¼‰
        symbol_code = stock_code[2:]
    else:
        # Aè‚¡ï¼šå»æ‰äº¤æ˜“æ‰€å‰ç¼€ï¼ˆå¦‚ sh600519 -> 600519ï¼‰
        symbol_code = stock_code[2:]
    
    # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    TIMEOUT_SECONDS = 30
    
    # ä½¿ç”¨threading.Timerå®ç°è¶…æ—¶æ§åˆ¶ï¼ˆWindowså…¼å®¹ï¼‰
    def fetch_with_timeout(func, *args, **kwargs):
        result = [None]
        exception = [None]
        
        def target():
            try:
                result[0] = func(*args, **kwargs)
            except Exception as e:
                exception[0] = e
        
        thread = threading.Thread(target=target)
        thread.daemon = True
        thread.start()
        thread.join(TIMEOUT_SECONDS)
        
        if thread.is_alive():
            # è¶…æ—¶ï¼Œçº¿ç¨‹ä»åœ¨è¿è¡Œ
            return None, TimeoutError("APIè°ƒç”¨è¶…æ—¶")
        
        if exception[0]:
            return None, exception[0]
        
        return result[0], None
    
    try:
        if is_hk_stock:
            # æ¸¯è‚¡æ•°æ®è·å–
            print(f"  ğŸ“¥ æ‹‰å–æ¸¯è‚¡ {symbol_code} çš„æ—¥æ•°æ®...")
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼š2020-01-01 -> 20200101
            start_date_str = START_DATE.replace('-', '')
            end_date_str = datetime.now().strftime('%Y%m%d')
            
            # ä½¿ç”¨ stock_hk_hist è·å–æ¸¯è‚¡å†å²æ•°æ®
            df_daily, error = fetch_with_timeout(
                ak.stock_hk_hist, 
                symbol=symbol_code, 
                period="daily", 
                start_date=start_date_str, 
                end_date=end_date_str, 
                adjust=""
            )
            
            if df_daily is not None and not df_daily.empty:
                print(f"  âœ… æˆåŠŸè·å–æ¸¯è‚¡ {len(df_daily)} æ¡æ—¥çº¿æ•°æ®")
            elif isinstance(error, TimeoutError):
                print(f"  âŒ æ¸¯è‚¡æ—¥çº¿æ•°æ®è·å–è¶…æ—¶")
                return None
            else:
                print(f"  âŒ æ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {error}")
                return None
        elif is_bj_stock:
            # åŒ—äº¤æ‰€æ•°æ®è·å–ï¼ˆåŒ—äº¤æ‰€ä¸æ”¯æŒqfqå‰å¤æƒï¼‰
            print(f"  ğŸ“¥ æ‹‰å–åŒ—äº¤æ‰€ {symbol_code} çš„æ—¥æ•°æ®...")
            
            # åŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨Aè‚¡æ¥å£ï¼Œä½†ä¸å¸¦qfqå‚æ•°
            df_daily, error = fetch_with_timeout(
                ak.stock_zh_a_hist, 
                symbol=symbol_code, 
                period="daily", 
                start_date=START_DATE
            )
            
            if df_daily is not None and not df_daily.empty:
                print(f"  âœ… æˆåŠŸè·å–åŒ—äº¤æ‰€ {len(df_daily)} æ¡æ—¥çº¿æ•°æ®")
            elif isinstance(error, TimeoutError):
                print(f"  âŒ åŒ—äº¤æ‰€æ—¥çº¿æ•°æ®è·å–è¶…æ—¶")
                return None
            else:
                print(f"  âŒ åŒ—äº¤æ‰€æ•°æ®è·å–å¤±è´¥: {error}")
                # å°è¯•å…¶ä»–æ–¹æ³•ï¼ˆå¦‚æœæœ‰ï¼‰
                return None
        else:
            # Aè‚¡æ•°æ®è·å–ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            print(f"  ğŸ“¥ æ‹‰å– {symbol_code} çš„æ—¥æ•°æ®...")
            
            # å°è¯•è·å–æ—¥çº¿æ•°æ®ï¼ˆå¸¦qfqå‚æ•°ï¼‰
            df_daily, error = fetch_with_timeout(ak.stock_zh_a_hist, symbol=symbol_code, period="daily", adjust="qfq", start_date=START_DATE)
            
            if df_daily is not None:
                print(f"  âœ… æˆåŠŸè·å– {len(df_daily)} æ¡æ—¥çº¿æ•°æ®")
            elif isinstance(error, TimeoutError):
                print(f"  â° æ—¥çº¿æ•°æ®è·å–è¶…æ—¶ï¼Œå°è¯•ä¸å¸¦qfqå‚æ•°...")
                # å°è¯•ä¸å¸¦qfqå‚æ•°
                df_daily, error = fetch_with_timeout(ak.stock_zh_a_hist, symbol=symbol_code, period="daily", start_date=START_DATE)
                if df_daily is not None:
                    print(f"  âœ… æˆåŠŸè·å– {len(df_daily)} æ¡æ—¥çº¿æ•°æ®")
                elif isinstance(error, TimeoutError):
                    print(f"  âŒ æ—¥çº¿æ•°æ®è·å–è¶…æ—¶")
                    return None
                else:
                    print(f"  âŒ äºŒæ¬¡å°è¯•ä¹Ÿå¤±è´¥: {error}")
                    return None
            else:
                print(f"  âŒ æ‹‰å–æ•°æ®å¤±è´¥: {error}")
                # å°è¯•ä¸å¸¦qfqå‚æ•°
                df_daily, error = fetch_with_timeout(ak.stock_zh_a_hist, symbol=symbol_code, period="daily", start_date=START_DATE)
                if df_daily is not None:
                    print(f"  âœ… æˆåŠŸè·å– {len(df_daily)} æ¡æ—¥çº¿æ•°æ®")
                elif isinstance(error, TimeoutError):
                    print(f"  âŒ æ—¥çº¿æ•°æ®è·å–è¶…æ—¶")
                    return None
                else:
                    print(f"  âŒ äºŒæ¬¡å°è¯•ä¹Ÿå¤±è´¥: {error}")
                    return None
        
        if df_daily is None or df_daily.empty:
            return None
    
    except Exception as e:
        print(f"  âŒ æ‹‰å–æ—¥çº¿æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        print(traceback.format_exc())
        return None
    
    return process_and_save_data(df_daily, stock_name, stock_code, excel_file)


def process_and_save_data(df_daily, name, code, excel_file):
    """å¤„ç†æ•°æ®å¹¶ä¿å­˜åˆ°Excelæ–‡ä»¶ï¼ˆä»…å¤„ç†è‚¡ç¥¨æ•°æ®ï¼‰"""
    # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
    if df_daily is None or df_daily.empty:
        print(f"âŒ è­¦å‘Š: {name}({code})æ²¡æœ‰è·å–åˆ°æ•°æ®")
        return None
    
    # æ•°æ®æ¸…æ´—
    print("  ğŸ§¹ æ•°æ®æ¸…æ´—ä¸­...")
    
    # é‡å‘½ååˆ—
    rename_map = {
        'æ—¥æœŸ': 'date',
        'æ—¶é—´': 'date',
        'æ”¶ç›˜ä»·': 'close',
        'å¼€ç›˜ä»·': 'open',
        'æœ€é«˜ä»·': 'high',
        'æœ€ä½ä»·': 'low',
        'æˆäº¤': 'volume',
        'æˆäº¤é‡': 'volume',
        'äº¤æ˜“é‡': 'volume',
        'æ”¶ç›˜': 'close',
        'å¼€ç›˜': 'open',
        'æœ€é«˜': 'high',
        'æœ€ä½': 'low',
        'Close': 'close',
        'Open': 'open',
        'High': 'high',
        'Low': 'low',
        'Volume': 'volume',
        'æˆäº¤é¢': 'amount',
        'Amount': 'amount',
        'AMOUNT': 'amount',
        'turnover': 'amount',
        'Turnover': 'amount',
        'é‡‘é¢': 'amount'
    }
    
    # åªé‡å‘½åå®é™…å­˜åœ¨çš„åˆ—
    for old_name, new_name in rename_map.items():
        if old_name in df_daily.columns:
            df_daily = df_daily.rename(columns={old_name: new_name})
    
    # æ·»åŠ æ—¥æœŸåˆ—å¦‚æœä¸å­˜åœ¨
    if 'date' not in df_daily.columns:
        if df_daily.index.name == 'date' or df_daily.index.name == 'æ—¥æœŸ':
            df_daily = df_daily.reset_index()
        else:
            df_daily['date'] = pd.to_datetime(df_daily.index)
    
    # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨ä¸”æœ‰æ•ˆ
    df_daily['date'] = pd.to_datetime(df_daily['date'], errors='coerce')
    
    # è¿‡æ»¤èµ·å§‹æ—¥æœŸ
    df_daily = df_daily[df_daily['date'] >= START_DATE]
    
    # æ£€æŸ¥å¹¶åˆ é™¤é‡å¤æ—¥æœŸ
    duplicate_dates = df_daily['date'].duplicated()
    if duplicate_dates.any():
        print(f"  ğŸ” å‘ç° {duplicate_dates.sum()} ä¸ªé‡å¤æ—¥æœŸï¼Œæ­£åœ¨åˆ é™¤...")
        df_daily = df_daily[~duplicate_dates]
    
    # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
    for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
        if col in df_daily.columns:
            if df_daily[col].dtype != 'float64' and df_daily[col].dtype != 'int64':
                df_daily[col] = pd.to_numeric(df_daily[col], errors='coerce')
    
    # å‰”é™¤åœç‰Œæ—¥æˆ–é›¶äº¤æ˜“é‡æ—¥
    if 'volume' in df_daily.columns:
        df_daily = df_daily[df_daily['volume'] > 0]
    
    # æ’åºæ•°æ®
    df_daily = df_daily.sort_values('date', ascending=True)
    
    # å¡«å……ç¼ºå¤±å€¼
    if df_daily.isnull().values.any():
        print("  ğŸ”§ å‘ç°ç¼ºå¤±å€¼ï¼Œæ­£åœ¨å¡«å……...")
        for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
            if col in df_daily.columns:
                df_daily[col] = df_daily[col].ffill().bfill()
        df_daily = df_daily.dropna()
    
    # æ£€æŸ¥å¹¶æ‰“å°æ—¥æœŸèŒƒå›´
    if len(df_daily) > 0:
        start_date = df_daily['date'].min()
        end_date = df_daily['date'].max()
        print(f"  ğŸ“Š æ—¥çº¿æ•°æ®é‡: {len(df_daily)} æ¡è®°å½•")
        print(f"  ğŸ“… æ—¥æœŸèŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
    else:
        print("  âŒ è­¦å‘Šï¼šæ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return None
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    print("  ğŸ§® è®¡ç®—æ—¥çº¿æŠ€æœ¯æŒ‡æ ‡...")
    try:
        print("    ğŸ“ˆ è®¡ç®—ç§»åŠ¨å¹³å‡çº¿(MA)...")
        df_daily = calculate_ma(df_daily)
        
        print("    ğŸ“ˆ è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿(EMA)...")
        df_daily = calculate_ema(df_daily)
        
        print("    ğŸ“Š è®¡ç®—MACDæŒ‡æ ‡...")
        df_daily = calculate_macd(df_daily)
        
        print("    ğŸ“Š è®¡ç®—KDJæŒ‡æ ‡...")
        df_daily = calculate_kdj(df_daily)
        
        print("    ğŸ“Š è®¡ç®—RSIæŒ‡æ ‡...")
        df_daily = calculate_rsi(df_daily)
        
        print("    ğŸ“Š è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡...")
        df_daily = calculate_boll(df_daily)
        
        print("    ğŸ“Š è®¡ç®—Trend Indicator A-V2...")
        df_daily = calculate_trend_indicator_a(df_daily)
        
        print("    ğŸ“Š è®¡ç®—SuperTrendæŒ‡æ ‡...")
        df_daily = calculate_supertrend(df_daily)
        
        print("    ğŸ“Š è®¡ç®—QQE MODæŒ‡æ ‡...")
        df_daily = calculate_qqe_mod(df_daily)
        
        print("  âœ… æ—¥çº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
    except Exception as e:
        print(f"  âŒ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        print(traceback.format_exc())
        return None
    
    # è·å–å°æ—¶çº¿æ•°æ®ï¼ˆå…ˆå°è¯•æ‹‰å–ï¼Œå¤±è´¥åä»æ—¥çº¿ç”Ÿæˆï¼‰
    print("    ğŸ“ˆ è·å–å°æ—¶çº¿æ•°æ®...")
    df_hourly = pd.DataFrame()
    
    # åˆ¤æ–­è‚¡ç¥¨ç±»å‹
    is_hk_stock = code.startswith('hk')
    is_bj_stock = code.startswith(('sz430', 'sz837', 'sz889', 'sz43', 'sz83', 'sz88'))
    
    # å…ˆå°è¯•ä»APIæ‹‰å–å°æ—¶çº¿æ•°æ®
    try:
        if is_hk_stock:
            # æ¸¯è‚¡æš‚æ—¶ä¸æ”¯æŒå°æ—¶çº¿æ•°æ®æ‹‰å–ï¼Œç›´æ¥ä»æ—¥çº¿ç”Ÿæˆ
            print(f"    âš ï¸  æ¸¯è‚¡æš‚ä¸æ”¯æŒå°æ—¶çº¿æ•°æ®æ‹‰å–ï¼Œå°†ä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
            df_hourly_raw = None
        elif is_bj_stock:
            # åŒ—äº¤æ‰€æš‚æ—¶ä¸æ”¯æŒå°æ—¶çº¿æ•°æ®æ‹‰å–ï¼Œç›´æ¥ä»æ—¥çº¿ç”Ÿæˆ
            print(f"    âš ï¸  åŒ—äº¤æ‰€æš‚ä¸æ”¯æŒå°æ—¶çº¿æ•°æ®æ‹‰å–ï¼Œå°†ä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
            df_hourly_raw = None
        else:
            # Aè‚¡å°è¯•æ‹‰å–å°æ—¶çº¿æ•°æ®
            df_hourly_raw = fetch_stock_data_hourly_china(code)
        
        if df_hourly_raw is not None and not df_hourly_raw.empty:
            # æ¸…æ´—å°æ—¶çº¿æ•°æ®ï¼ˆä½¿ç”¨ä¸æ—¥çº¿æ•°æ®ç›¸åŒçš„æ¸…æ´—é€»è¾‘ï¼‰
            print("    ğŸ§¹ æ¸…æ´—å°æ—¶çº¿æ•°æ®...")
            # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨ä¸”æœ‰æ•ˆ
            if 'date' not in df_hourly_raw.columns:
                if df_hourly_raw.index.name == 'date' or df_hourly_raw.index.name == 'æ—¥æœŸ':
                    df_hourly_raw = df_hourly_raw.reset_index()
                else:
                    df_hourly_raw['date'] = pd.to_datetime(df_hourly_raw.index)
            
            df_hourly_raw['date'] = pd.to_datetime(df_hourly_raw['date'], errors='coerce')
            
            # å¤„ç†æ—¶åŒºï¼šå¦‚æœæ—¥æœŸåˆ—æ˜¯tz-awareï¼Œè½¬æ¢ä¸ºUTCæ—¶åŒºç„¶åå»æ‰æ—¶åŒºä¿¡æ¯
            if pd.api.types.is_datetime64tz_dtype(df_hourly_raw['date']):
                df_hourly_raw['date'] = df_hourly_raw['date'].dt.tz_convert('UTC').dt.tz_localize(None)
            
            # è¿‡æ»¤èµ·å§‹æ—¥æœŸ
            start_date_pd = pd.to_datetime(START_DATE)
            df_hourly_raw = df_hourly_raw[df_hourly_raw['date'] >= start_date_pd]
            
            # åˆ é™¤é‡å¤æ—¥æœŸ
            if df_hourly_raw['date'].duplicated().any():
                print(f"    ğŸ” å‘ç°é‡å¤æ—¥æœŸï¼Œæ­£åœ¨åˆ é™¤...")
                df_hourly_raw = df_hourly_raw.drop_duplicates(subset=['date'])
            
            # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
            for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
                if col in df_hourly_raw.columns:
                    if not pd.api.types.is_numeric_dtype(df_hourly_raw[col]):
                        df_hourly_raw[col] = pd.to_numeric(df_hourly_raw[col], errors='coerce')
            
            # æ’åºæ•°æ®
            df_hourly_raw = df_hourly_raw.sort_values('date', ascending=True)
            
            # å¡«å……ç¼ºå¤±å€¼
            if df_hourly_raw.isnull().values.any():
                print("    ğŸ”§ å‘ç°ç¼ºå¤±å€¼ï¼Œæ­£åœ¨å¡«å……...")
                for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
                    if col in df_hourly_raw.columns:
                        df_hourly_raw[col] = df_hourly_raw[col].ffill().bfill()
                df_hourly_raw = df_hourly_raw.dropna()
            
            df_hourly = df_hourly_raw.copy()
            
            # æ£€æŸ¥æ¸…æ´—åçš„æ•°æ®æ˜¯å¦ä¸ºç©º
            if len(df_hourly) > 0:
                print(f"    âœ… æˆåŠŸæ‹‰å–å°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡è®°å½•")
            else:
                print(f"    âš ï¸  æ¸…æ´—åå°æ—¶çº¿æ•°æ®ä¸ºç©ºï¼Œå°†ä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
                df_hourly = generate_hourly_view(df_daily.copy())
                print(f"    ğŸ“Š ä»æ—¥çº¿ç”Ÿæˆå°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡è®°å½•")
        else:
            print(f"    âš ï¸  æ— æ³•æ‹‰å–å°æ—¶çº¿æ•°æ®ï¼Œå°†ä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
            df_hourly = generate_hourly_view(df_daily.copy())
            print(f"    ğŸ“Š ä»æ—¥çº¿ç”Ÿæˆå°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡è®°å½•")
    except Exception as e:
        print(f"    âš ï¸  æ‹‰å–å°æ—¶çº¿æ•°æ®å¤±è´¥: {e}ï¼Œå°†ä»æ—¥çº¿æ•°æ®ç”Ÿæˆ...")
        print(traceback.format_exc())
        try:
            df_hourly = generate_hourly_view(df_daily.copy())
            print(f"    ğŸ“Š ä»æ—¥çº¿ç”Ÿæˆå°æ—¶çº¿æ•°æ®: {len(df_hourly)} æ¡è®°å½•")
        except Exception as e2:
            print(f"    âŒ ç”Ÿæˆå°æ—¶çº¿æ•°æ®æ—¶å‡ºé”™: {e2}")
            df_hourly = pd.DataFrame()
    
    # è®¡ç®—å°æ—¶çº¿æŒ‡æ ‡
    if not df_hourly.empty:
        try:
            print("    ğŸ§® è®¡ç®—å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡...")
            df_hourly = calculate_ma(df_hourly)
            df_hourly = calculate_ema(df_hourly)
            df_hourly = calculate_macd(df_hourly)
            df_hourly = calculate_kdj(df_hourly)
            df_hourly = calculate_rsi(df_hourly)
            df_hourly = calculate_boll(df_hourly)
            df_hourly = calculate_trend_indicator_a(df_hourly)
            df_hourly = calculate_supertrend(df_hourly)
            df_hourly = calculate_qqe_mod(df_hourly)
            print("    âœ… å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
        except Exception as e:
            print(f"    âŒ è®¡ç®—å°æ—¶çº¿æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            print(traceback.format_exc())
    
    # ç”Ÿæˆå‘¨çº¿è§†å›¾
    try:
        print("    ğŸ“ˆ ç”Ÿæˆå‘¨çº¿æ•°æ®...")
        df_weekly = generate_weekly_view(df_daily.copy())
        print(f"    ğŸ“Š å‘¨çº¿æ•°æ®é‡: {len(df_weekly)} æ¡è®°å½•")
        
        # è®¡ç®—å‘¨çº¿æŒ‡æ ‡
        if not df_weekly.empty:
            print("    ğŸ§® è®¡ç®—å‘¨çº¿æŠ€æœ¯æŒ‡æ ‡...")
            df_weekly = calculate_ma(df_weekly)
            df_weekly = calculate_ema(df_weekly)
            df_weekly = calculate_macd(df_weekly)
            df_weekly = calculate_kdj(df_weekly)
            df_weekly = calculate_rsi(df_weekly)
            df_weekly = calculate_boll(df_weekly)
            df_weekly = calculate_trend_indicator_a(df_weekly)
            df_weekly = calculate_supertrend(df_weekly)
            df_weekly = calculate_qqe_mod(df_weekly)
            print("    âœ… å‘¨çº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
    except Exception as e:
        print(f"  âŒ ç”Ÿæˆå‘¨çº¿æ•°æ®æ—¶å‡ºé”™: {e}")
        print(traceback.format_exc())
        df_weekly = pd.DataFrame()
    
    # ç”Ÿæˆæœˆçº¿è§†å›¾
    try:
        print("    ğŸ“ˆ ç”Ÿæˆæœˆçº¿æ•°æ®...")
        df_monthly = generate_monthly_view(df_daily.copy())
        print(f"    ğŸ“Š æœˆçº¿æ•°æ®é‡: {len(df_monthly)} æ¡è®°å½•")
        
        # è®¡ç®—æœˆçº¿æŒ‡æ ‡
        if not df_monthly.empty:
            print("    ğŸ§® è®¡ç®—æœˆçº¿æŠ€æœ¯æŒ‡æ ‡...")
            df_monthly = calculate_ma(df_monthly)
            df_monthly = calculate_ema(df_monthly)
            df_monthly = calculate_macd(df_monthly)
            df_monthly = calculate_kdj(df_monthly)
            df_monthly = calculate_rsi(df_monthly)
            df_monthly = calculate_boll(df_monthly)
            df_monthly = calculate_trend_indicator_a(df_monthly)
            df_monthly = calculate_supertrend(df_monthly)
            df_monthly = calculate_qqe_mod(df_monthly)
            print("    âœ… æœˆçº¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
    except Exception as e:
        print(f"  âŒ ç”Ÿæˆæœˆçº¿æ•°æ®æ—¶å‡ºé”™: {e}")
        print(traceback.format_exc())
        df_monthly = pd.DataFrame()
    
    # ä¿å­˜åˆ°Excelæ–‡ä»¶
    print("  ğŸ’¾ ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶...")
    save_data_to_excel(df_daily, df_hourly, df_weekly, df_monthly, excel_file)
    print(f"  âœ… æ•°æ®å·²ä¿å­˜: {excel_file}")
    
    return excel_file

def main():
    """ä¸»å‡½æ•°ï¼šå‡†å¤‡æ‰€æœ‰è‚¡ç¥¨æ•°æ® - æ”¯æŒåˆ†æ®µå¤„ç†å’Œæ–­ç‚¹ç»­ä¼ """
    start_time = time.time()
    
    print("=" * 80)
    print("ğŸ“Š è‚¡ç¥¨æ•°æ®å‡†å¤‡ç³»ç»Ÿå¯åŠ¨ - åˆ†æ®µå¤„ç†æ¨¡å¼")
    print(f"ğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨
    print("ğŸ“‹ æ­£åœ¨åŠ è½½è‚¡ç¥¨åˆ—è¡¨...")
    stock_list = get_hs300_stocks()
    total_stocks = len(stock_list)
    
    if total_stocks == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è‚¡ç¥¨æ•°æ®ï¼Œè¯·æ£€æŸ¥hs300_stocks.csvæ–‡ä»¶")
        return
    
    print(f"âœ… åŠ è½½å®Œæˆ: {total_stocks} åªè‚¡ç¥¨")
    
    # åˆ†æ®µå¤„ç†é…ç½®
    BATCH_SIZE = 20  # æ¯æ‰¹å¤„ç†20åªè‚¡ç¥¨
    BATCH_REST_TIME = 10  # æ¯æ‰¹ä¹‹é—´ä¼‘æ¯10ç§’
    STOCK_REST_TIME = 3  # æ¯åªè‚¡ç¥¨ä¹‹é—´ä¼‘æ¯3ç§’
    PROGRESS_FILE = "processing_progress.json"  # è¿›åº¦ä¿å­˜æ–‡ä»¶
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–­ç‚¹ç»­ä¼ 
    start_index = 0
    if os.path.exists(PROGRESS_FILE):
        try:
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
                start_index = progress_data.get('last_processed_index', 0)
                print(f"ğŸ”„ å‘ç°æ–­ç‚¹ç»­ä¼ æ–‡ä»¶ï¼Œä»ç¬¬ {start_index + 1} åªè‚¡ç¥¨å¼€å§‹ç»§ç»­å¤„ç†")
        except Exception as e:
            print(f"âš ï¸  è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}ï¼Œä»å¤´å¼€å§‹å¤„ç†")
            start_index = 0
    
    # å¼€å§‹å¤„ç†è‚¡ç¥¨
    print("\n" + "=" * 80)
    print(f"ğŸš€ å¼€å§‹å¤„ç†è‚¡ç¥¨æ•°æ® ({total_stocks} åªè‚¡ç¥¨) - åˆ†æ®µå¤„ç†æ¨¡å¼")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} | æ‰¹æ¬¡é—´éš”: {BATCH_REST_TIME}ç§’ | è‚¡ç¥¨é—´éš”: {STOCK_REST_TIME}ç§’")
    print("=" * 80)
    
    # å‡†å¤‡æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    processed_files = []
    stock_start_time = time.time()
    
    # è®¡ç®—æ€»æ‰¹æ¬¡æ•°
    total_batches = (total_stocks - start_index + BATCH_SIZE - 1) // BATCH_SIZE
    
    for batch_idx in range(total_batches):
        batch_start = start_index + batch_idx * BATCH_SIZE
        batch_end = min(start_index + (batch_idx + 1) * BATCH_SIZE, total_stocks)
        current_batch_size = batch_end - batch_start
        
        print(f"\n" + "=" * 60)
        print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}: å¤„ç†ç¬¬ {batch_start + 1}-{batch_end} åªè‚¡ç¥¨")
        print(f"ğŸ“Š æœ¬æ‰¹æ¬¡: {current_batch_size} åªè‚¡ç¥¨")
        print("=" * 60)
        
        batch_start_time = time.time()
        
        for idx in range(batch_start, batch_end):
            current_time = time.time()
            elapsed_time = current_time - start_time
            progress_percent = ((idx + 1) / total_stocks) * 100
            remaining_stocks = total_stocks - idx - 1
            
            print(f"\nğŸ“ˆ [{idx+1}/{total_stocks}] ({progress_percent:.1f}%) å¤„ç†è‚¡ç¥¨: {stock_list[idx][1]}({stock_list[idx][0]})")
            if idx > 0:
                print(f"â±ï¸  å·²ç”¨æ—¶é—´: {elapsed_time:.1f}ç§’ | é¢„è®¡å‰©ä½™: {((elapsed_time/(idx+1))*(remaining_stocks)):.1f}ç§’")
            
            try:
                # è®¾ç½®å•ä¸ªè‚¡ç¥¨çš„è¶…æ—¶æ—¶é—´
                stock_start = time.time()
                excel_file = prepare_stock_data(stock_list[idx][0], stock_list[idx][1])
                stock_elapsed = time.time() - stock_start
                
                if excel_file:
                    processed_files.append((f"è‚¡ç¥¨_{stock_list[idx][0]}", stock_list[idx][1], excel_file))
                    print(f"âœ… è‚¡ç¥¨ {stock_list[idx][1]} å¤„ç†æˆåŠŸï¼Œè€—æ—¶: {stock_elapsed:.2f}ç§’")
                else:
                    print(f"âŒ è‚¡ç¥¨ {stock_list[idx][1]} å¤„ç†å¤±è´¥ï¼Œè€—æ—¶: {stock_elapsed:.2f}ç§’")
            except Exception as e:
                print(f"âŒ å¤„ç†è‚¡ç¥¨ {stock_list[idx][1]}({stock_list[idx][0]}) æ—¶å‡ºé”™: {e}")
                print(traceback.format_exc())
            
            # ä¿å­˜è¿›åº¦
            try:
                progress_data = {
                    'last_processed_index': idx,
                    'last_processed_time': datetime.now().isoformat(),
                    'total_processed': len(processed_files),
                    'total_stocks': total_stocks
                }
                with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(progress_data, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
            
            # æ¯åªè‚¡ç¥¨ä¹‹é—´ä¼‘æ¯
            if idx + 1 < batch_end:
                print(f"â¸ï¸  ä¼‘æ¯ {STOCK_REST_TIME} ç§’...")
                time.sleep(STOCK_REST_TIME)
        
        # æ‰¹æ¬¡å®Œæˆç»Ÿè®¡
        batch_end_time = time.time()
        batch_elapsed = batch_end_time - batch_start_time
        print(f"\nâœ… æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆ! æœ¬æ‰¹æ¬¡ç”¨æ—¶: {batch_elapsed:.1f}ç§’")
        
        # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼ˆé™¤äº†æœ€åä¸€æ‰¹ï¼‰
        if batch_idx + 1 < total_batches:
            print(f"â¸ï¸  æ‰¹æ¬¡é—´ä¼‘æ¯ {BATCH_REST_TIME} ç§’...")
            time.sleep(BATCH_REST_TIME)
    
    stock_end_time = time.time()
    stock_elapsed = stock_end_time - stock_start_time
    print(f"\nâœ… æ‰€æœ‰è‚¡ç¥¨æ•°æ®å¤„ç†å®Œæˆ! æ€»ç”¨æ—¶: {stock_elapsed:.1f}ç§’")
    
    # åˆ é™¤è¿›åº¦æ–‡ä»¶
    if os.path.exists(PROGRESS_FILE):
        try:
            os.remove(PROGRESS_FILE)
            print("ğŸ—‘ï¸  è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
    
    # è®¡ç®—æ€»ç”¨æ—¶
    total_elapsed = time.time() - start_time
    
    # æ‰“å°å¤„ç†ç»“æœæ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“Š è‚¡ç¥¨æ•°æ®å¤„ç†å®Œæˆæ€»ç»“")
    print("=" * 80)
    print(f"âœ… æˆåŠŸå¤„ç†: {len(processed_files)}/{total_stocks} åªè‚¡ç¥¨")
    print(f"â±ï¸  æ€»ç”¨æ—¶: {total_elapsed:.1f}ç§’")
    print(f"âš¡ å¹³å‡é€Ÿåº¦: {total_stocks/total_elapsed:.2f} åª/åˆ†é’Ÿ")
    
    # æ‰¾å‡ºå¤±è´¥çš„è‚¡ç¥¨
    stock_failures = []
    for code, name in stock_list:
        if not any(p_id == f"è‚¡ç¥¨_{code}" for p_id, _, _ in processed_files):
            stock_failures.append((f"è‚¡ç¥¨_{code}", name))
    
    # æŠ¥å‘Šå¤±è´¥æƒ…å†µ
    if stock_failures:
        print(f"\nâŒ å¤±è´¥çš„è‚¡ç¥¨ ({len(stock_failures)} åª):")
        for code, name in stock_failures:
            print(f"  - {name}({code.replace('è‚¡ç¥¨_', '')})")
    
    if not stock_failures:
        print("\nğŸ‰ æ‰€æœ‰è‚¡ç¥¨éƒ½å¤„ç†æˆåŠŸï¼")
    
    print("\n" + "=" * 80)
    print("ğŸ“ æ•°æ®ä¿å­˜ä½ç½®")
    print("=" * 80)
    print(f"ğŸ“ˆ è‚¡ç¥¨æ•°æ®: 'stock_data' ç›®å½•")
    print(f"ğŸ• å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # åˆ†æ®µå¤„ç†å®Œæˆæç¤º
    print("\n" + "=" * 80)
    print("ğŸ¯ åˆ†æ®µå¤„ç†æ¨¡å¼è¯´æ˜")
    print("=" * 80)
    print("âœ… æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœè„šæœ¬ä¸­æ–­ï¼Œé‡æ–°è¿è¡Œä¼šä»ä¸Šæ¬¡åœæ­¢çš„åœ°æ–¹ç»§ç»­")
    print("âœ… æ‰¹æ¬¡å¤„ç†ï¼šæ¯æ‰¹å¤„ç†20åªè‚¡ç¥¨ï¼Œæ‰¹æ¬¡é—´ä¼‘æ¯10ç§’")
    print("âœ… æ™ºèƒ½ä¼‘æ¯ï¼šæ¯åªè‚¡ç¥¨é—´ä¼‘æ¯3ç§’ï¼Œé¿å…APIé™æµ")
    print("âœ… è¿›åº¦ä¿å­˜ï¼šå®æ—¶ä¿å­˜å¤„ç†è¿›åº¦åˆ° processing_progress.json")
    print("âœ… è‡ªåŠ¨æ¸…ç†ï¼šå¤„ç†å®Œæˆåè‡ªåŠ¨æ¸…ç†è¿›åº¦æ–‡ä»¶")
    print("=" * 80)


if __name__ == "__main__":
    # åªå¤„ç†è‚¡ç¥¨æ•°æ®
    print("ğŸ¯ è¿è¡Œæ¨¡å¼ï¼šå¤„ç†è‚¡ç¥¨æ•°æ®")
    main()